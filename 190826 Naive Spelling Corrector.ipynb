{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alx/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/alx/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to /home/alx/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/alx/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.models.spelling_correction.levenshtein.searcher_component import LevenshteinSearcherComponent\n",
    "import numpy as np\n",
    "DATA_PATH = \"/home/alx/Cloud/spell_corr/py_spelling_corrector/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LanguageModel():\n",
    "    def tokenize(self, sent_str):\n",
    "        pass\n",
    "\n",
    "    def estimate_likelihood(self, sent_str):\n",
    "        pass\n",
    "\n",
    "    def score_sentences(self, sentences):\n",
    "        return np.random.rand(len(sentences))\n",
    "\n",
    "class Hypothesis():\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.score = np.nan\n",
    "\n",
    "    def fork_for_each_suffix(self, suffixes):\n",
    "        \"\"\"Given a list of suffixes strings it forks the current hypotheses into several\n",
    "        hypotheses for each suffix\"\"\"\n",
    "        hypotheses_list = []\n",
    "        for each_suffix in suffixes:\n",
    "            hypotheses_list.append(Hypothesis(self.text + each_suffix))\n",
    "\n",
    "        return hypotheses_list\n",
    "        \n",
    "    def __str__(self):\n",
    "        if self.score:\n",
    "            out_text = \" score: %f\" % self.score\n",
    "        else:\n",
    "            out_text = \"\"\n",
    "        text = \"hypothesis: %s\" % self.text\n",
    "        return text + out_text\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.score:\n",
    "            out_text = \" score: %f\" % self.score\n",
    "        else:\n",
    "            out_text = \"\"\n",
    "        text = \"hypothesis: %s\" % self.text\n",
    "        return text + out_text\n",
    "    \n",
    "class HypothesesHub():\n",
    "    def __init__(self):\n",
    "        # init with null hypothesis:\n",
    "        self.hypotheses = [Hypothesis(\"\")]\n",
    "        \n",
    "        self.lm = LanguageModel()\n",
    "\n",
    "        # hypotheses which are 20% lower probable are pruuned:\n",
    "        self.prob_pruning_treshold = 0.8\n",
    "\n",
    "        self.max_score = 0.0\n",
    "\n",
    "    def get_scores(self):\n",
    "        scores = [each_hypo.score for each_hypo in self.hypotheses]\n",
    "        return scores\n",
    "\n",
    "    def append_partial_hypotheses(self, partial_candidates):\n",
    "        \"\"\"\n",
    "        For each hypothesis in the hub it appends all candidates\n",
    "        :param partial_candidates:\n",
    "        :return: updated self\n",
    "        \"\"\"\n",
    "        new_hypotheses = []\n",
    "        if self.hypotheses:\n",
    "            for each_hypothesis in self.hypotheses:\n",
    "                hypos = each_hypothesis.fork_for_each_suffix(partial_candidates)\n",
    "                new_hypotheses += hypos\n",
    "        self.hypotheses = new_hypotheses\n",
    "        return self\n",
    "\n",
    "    def score_hypotheses(self):\n",
    "        \"\"\"\n",
    "        Command to run scoring of all hypotheses by language model scoring function\n",
    "        :return: list of scored hypotheses\n",
    "        \"\"\"\n",
    "        sentences = [each_hypo.text for each_hypo in self.hypotheses]\n",
    "        scores = self.lm.score_sentences(sentences)\n",
    "\n",
    "        for num, each_hypo in enumerate(self.hypotheses):\n",
    "            each_hypo.score = scores[num]\n",
    "        return self.hypotheses\n",
    "\n",
    "    def prune_low_prob_hypotheses(self, prob_pruning_treshold=None, max_number_of_hypotheses=100):\n",
    "        \"\"\"\n",
    "        Prunes hypotheses that has probability lower than treshold value.\n",
    "        treshold value depends on value of max prob hypothesis.\n",
    "\n",
    "        :param prob_pruning_treshold: [0,1] ratio of max probability that is required for a\n",
    "        hypothesis to be kept in hypotheses hub\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # number check\n",
    "        if len(self.hypotheses)>max_number_of_hypotheses:\n",
    "            # prune those which are the worst\n",
    "            filtered_hypotheses = sorted(self.hypotheses, key=lambda x: x.score, reverse=True)\n",
    "            self.hypotheses = filtered_hypotheses[:max_number_of_hypotheses]\n",
    "\n",
    "        # prune by prob value\n",
    "        if not prob_pruning_treshold:\n",
    "            prob_pruning_treshold = self.prob_pruning_treshold\n",
    "\n",
    "        scores = self.get_scores()\n",
    "        # prune low probs\n",
    "        max_score = max(scores)\n",
    "        # finmd all that below\n",
    "        lowest_allowed_prob = max_score * prob_pruning_treshold\n",
    "\n",
    "        filtered_hypotheses = [each_hypo for idx, each_hypo in\n",
    "                               enumerate(self.hypotheses) if\n",
    "                               each_hypo.score >= lowest_allowed_prob]\n",
    "        self.hypotheses = filtered_hypotheses        \n",
    "            \n",
    "        return self.hypotheses\n",
    "\n",
    "\n",
    "class SpellingCorrectionCandidatesGenerator():\n",
    "    def __init__(self, path_to_dictionary=None):\n",
    "\n",
    "        words_dict = []\n",
    "        if not path_to_dictionary:\n",
    "            path_to_dictionary = DATA_PATH + \"compreno_wordforms.txt\"\n",
    "#             path_to_dictionary = DATA_PATH + \"russian_words_vocab.dict\"\n",
    "        \n",
    "        with open(path_to_dictionary, \"r\") as dict_file:\n",
    "            words_dict = dict_file.read().splitlines()\n",
    "        self.lsc = LevenshteinSearcherComponent(words=words_dict)\n",
    "\n",
    "    def gen_candidates(self, token):\n",
    "        \"\"\"\n",
    "        Given a token striung generates candidates\n",
    "        :param token:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        scored_candidates=self.lsc([[token]])[0][0]\n",
    "        scores, w_forms = zip(*scored_candidates)\n",
    "        w_forms = list(w_forms)\n",
    "        scores = list(scores)\n",
    "        # ############################################################################################\n",
    "        # here is rule based/statistical substitutions with distant levenshtein can be applied:\n",
    "        FREQUENT_ERRORS_DECREMENT_SCORE = -1.0\n",
    "        if token == \"нить\":\n",
    "            w_forms.append(\"нибудь\")\n",
    "            scores.append(FREQUENT_ERRORS_DECREMENT_SCORE)        \n",
    "        elif token in [\"оч\"]:\n",
    "            w_forms.append(\"очень\")\n",
    "            scores.append(FREQUENT_ERRORS_DECREMENT_SCORE)\n",
    "        elif token in [\"што\", \"шо\", \"чо\", \"чё\"]:\n",
    "            w_forms.append(\"что\")\n",
    "            scores.append(FREQUENT_ERRORS_DECREMENT_SCORE)\n",
    "        elif token in [\"ваще\", \"воще\"]:\n",
    "            w_forms.append(\"вообще\")\n",
    "            scores.append(FREQUENT_ERRORS_DECREMENT_SCORE)\n",
    "        elif token in [\"вообщем\"]:\n",
    "            w_forms.append(\"в общем\")\n",
    "            scores.append(FREQUENT_ERRORS_DECREMENT_SCORE)        \n",
    "        elif token in [\"писят\"]:\n",
    "            w_forms.append(\"пятьдесят\")\n",
    "            scores.append(FREQUENT_ERRORS_DECREMENT_SCORE)\n",
    "        elif token in [\"аццкий\"]:\n",
    "            w_forms.append(\"адский\")\n",
    "            scores.append(FREQUENT_ERRORS_DECREMENT_SCORE)\n",
    "        return scores, w_forms\n",
    "\n",
    "    def variate_with_prefixes(self, candidates):\n",
    "        \"\"\"\n",
    "        Given a tokens candidates this method enriches the space of candidates with prefixed variants\n",
    "        by default it prepends prefixes of the space and hyphen to tokens.\n",
    "\n",
    "        So [\"то\"] -> [\"то\", \"-то\", \" то\"]\n",
    "\n",
    "        :param candidates: list of candidate strings\n",
    "        :param prefixes: list of possible prefixes\n",
    "        :return: list of candidates enriched with prefixed versions\n",
    "        \"\"\"\n",
    "        \n",
    "#         prefixes = [\" \", \"-\"]\n",
    "        result_candidates = []\n",
    "        for each_candidate in candidates:\n",
    "            # add raw candidate:\n",
    "            result_candidates.append(each_candidate)\n",
    "            \n",
    "            # add space candidate\n",
    "            result_candidates.append(\" \" + each_candidate)\n",
    "            \n",
    "            # add hyphen candidates conditionally:\n",
    "            # TODO improve heuristics for hyphen adding?\n",
    "            # TODO add hyphen after \"по\"\n",
    "            if each_candidate in [\"то\", \"таки\", \"нибудь\", \"моему\", \"нашему\", \"твоему\", \"любому\", \"за\", \"другому\", \"как\",\n",
    "                                 \"русски\", \"разному\"]:\n",
    "                result_candidates.append(\"-\" + each_candidate)\n",
    "\n",
    "        return result_candidates\n",
    "    \n",
    "class SpellingCorrector():\n",
    "    # language_model;\n",
    "    # error model;\n",
    "    def __init__(self):\n",
    "        self.sccg = SpellingCorrectionCandidatesGenerator()\n",
    "    \n",
    "    def lowercase(self, sent_str):\n",
    "        return sent_str.lower()\n",
    "    \n",
    "    def _tokenize(self, sent_str):\n",
    "        return sent_str.split()\n",
    "\n",
    "    def generate_hypotheses_for_token(self, token):\n",
    "\n",
    "        pass\n",
    "\n",
    "    # def generate_hypotheses_for_sentence(self, tokenized_sentence):\n",
    "    #\n",
    "    #     for each_tok in tokenized_sentence:\n",
    "    #         # generate hypothesys for token\n",
    "    #         tok_hypotheses = self.generate_hypotheses_for_token(each_tok)\n",
    "\n",
    "\n",
    "    def predict_correct(self, sentence_str):\n",
    "        \"\"\"\n",
    "        predicts correction of the sentence\n",
    "        :param sentence_str:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def analyze_sentence(self, sentence):\n",
    "        \"\"\"\n",
    "\n",
    "        :param sentence: str, sentence with errors\n",
    "        :return: the best hypotheses of the sentence\n",
    "        \"\"\"\n",
    "        hypo_hub = HypothesesHub()\n",
    "        # preprocessing:\n",
    "        # TODO make lowercasing revertible:\n",
    "        sentence = self.lowercase(sentence)        \n",
    "        tokenized_input = self._tokenize(sentence)\n",
    "\n",
    "        for idx, each_tok in enumerate(tokenized_input):\n",
    "            scores, candidates = self.sccg.gen_candidates(each_tok)\n",
    "            if idx>0:\n",
    "                candidates = self.sccg.variate_with_prefixes(candidates)\n",
    "\n",
    "            hypo_hub = hypo_hub.append_partial_hypotheses(candidates)\n",
    "            hypo_hub.score_hypotheses()\n",
    "            hypo_hub.prune_low_prob_hypotheses()\n",
    "\n",
    "        return hypo_hub.hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SpellingCorrector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Привед', 'ватрушка']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = sc._tokenize(\"Привед ватрушка\")\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[(-8.0, 'Привед')]]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.sccg.lsc([[\"Привед\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-4.0, 'привез'),\n",
       " (-4.0, 'привей'),\n",
       " (-4.0, 'привел'),\n",
       " (-4.0, 'привес'),\n",
       " (-4.0, 'привет'),\n",
       " (-4.0, 'приведи'),\n",
       " (-4.0, 'приведу'),\n",
       " (-4.0, 'приведя'),\n",
       " (-4.0, 'привад'),\n",
       " (-4.0, 'привод'),\n",
       " (-4.0, 'присед'),\n",
       " (-4.0, 'при ед'),\n",
       " (-4.0, 'пр вед'),\n",
       " (-4.0, 'при вед'),\n",
       " (-8.0, 'привед')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_candidates = sc.sccg.gen_candidates(\"привед\")\n",
    "scored_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, w_forms = (zip(*scored_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('привез',\n",
       " 'привей',\n",
       " 'привел',\n",
       " 'привес',\n",
       " 'привет',\n",
       " 'приведи',\n",
       " 'приведу',\n",
       " 'приведя',\n",
       " 'привад',\n",
       " 'привод',\n",
       " 'присед',\n",
       " 'при ед',\n",
       " 'пр вед',\n",
       " 'при вед',\n",
       " 'привед')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['привез',\n",
       " '-привез',\n",
       " ' привез',\n",
       " 'привей',\n",
       " '-привей',\n",
       " ' привей',\n",
       " 'привел',\n",
       " '-привел',\n",
       " ' привел',\n",
       " 'привес',\n",
       " '-привес',\n",
       " ' привес',\n",
       " 'привет',\n",
       " '-привет',\n",
       " ' привет',\n",
       " 'приведи',\n",
       " '-приведи',\n",
       " ' приведи',\n",
       " 'приведу',\n",
       " '-приведу',\n",
       " ' приведу',\n",
       " 'приведя',\n",
       " '-приведя',\n",
       " ' приведя',\n",
       " 'привад',\n",
       " '-привад',\n",
       " ' привад',\n",
       " 'привод',\n",
       " '-привод',\n",
       " ' привод',\n",
       " 'присед',\n",
       " '-присед',\n",
       " ' присед',\n",
       " 'при ед',\n",
       " '-при ед',\n",
       " ' при ед',\n",
       " 'пр вед',\n",
       " '-пр вед',\n",
       " ' пр вед',\n",
       " 'при вед',\n",
       " '-при вед',\n",
       " ' при вед',\n",
       " 'привед',\n",
       " '-привед',\n",
       " ' привед']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_hypos = sc.sccg.variate_with_prefixes(w_forms, prefixes=['-', ' '])\n",
    "part_hypos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.HypothesesHub at 0x7f7f2cbe7128>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo_hub = HypothesesHub()\n",
    "hypo_hub.hypotheses = [Hypothesis(\"\")]\n",
    "hypo_hub.append_partial_hypotheses(part_hypos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Hypothesis at 0x7f7f2cc31630>,\n",
       " <__main__.Hypothesis at 0x7f7f2cc314e0>,\n",
       " <__main__.Hypothesis at 0x7f7f2cc316a0>,\n",
       " <__main__.Hypothesis at 0x7f7f2cc31668>,\n",
       " <__main__.Hypothesis at 0x7f7f2c646668>,\n",
       " <__main__.Hypothesis at 0x7f7f2c6464e0>,\n",
       " <__main__.Hypothesis at 0x7f7f2c6460b8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c646208>,\n",
       " <__main__.Hypothesis at 0x7f7f2c646630>,\n",
       " <__main__.Hypothesis at 0x7f7f2c6466a0>,\n",
       " <__main__.Hypothesis at 0x7f7f2c6466d8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c646710>,\n",
       " <__main__.Hypothesis at 0x7f7f2c646780>,\n",
       " <__main__.Hypothesis at 0x7f7f2c6467b8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c6467f0>,\n",
       " <__main__.Hypothesis at 0x7f7f2c646a58>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f198>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f1d0>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f208>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f240>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f278>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f2b0>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f2e8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f320>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f358>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f390>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f3c8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f400>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f6d8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f9e8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fa20>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fa58>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fa90>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fac8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fb00>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fb38>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fb70>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23e438>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23e518>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23ea58>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23ea90>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23e978>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23eb00>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23e6d8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23e6a0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo_hub.hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Hypothesis at 0x7f7f2cc31630>,\n",
       " <__main__.Hypothesis at 0x7f7f2cc314e0>,\n",
       " <__main__.Hypothesis at 0x7f7f2cc316a0>,\n",
       " <__main__.Hypothesis at 0x7f7f2cc31668>,\n",
       " <__main__.Hypothesis at 0x7f7f2c646668>,\n",
       " <__main__.Hypothesis at 0x7f7f2c6464e0>,\n",
       " <__main__.Hypothesis at 0x7f7f2c6460b8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c646208>,\n",
       " <__main__.Hypothesis at 0x7f7f2c646630>,\n",
       " <__main__.Hypothesis at 0x7f7f2c6466a0>,\n",
       " <__main__.Hypothesis at 0x7f7f2c6466d8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c646710>,\n",
       " <__main__.Hypothesis at 0x7f7f2c646780>,\n",
       " <__main__.Hypothesis at 0x7f7f2c6467b8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c6467f0>,\n",
       " <__main__.Hypothesis at 0x7f7f2c646a58>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f198>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f1d0>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f208>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f240>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f278>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f2b0>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f2e8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f320>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f358>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f390>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f3c8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f400>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f6d8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70f9e8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fa20>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fa58>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fa90>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fac8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fb00>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fb38>,\n",
       " <__main__.Hypothesis at 0x7f7f2c70fb70>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23e438>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23e518>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23ea58>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23ea90>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23e978>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23eb00>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23e6d8>,\n",
       " <__main__.Hypothesis at 0x7f7f2c23e6a0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo_hub.score_hypotheses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo_hub.hypotheses[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, words = sc.sccg.gen_candidates(\"привед\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('привез',\n",
       " 'привей',\n",
       " 'привел',\n",
       " 'привес',\n",
       " 'привет',\n",
       " 'приведи',\n",
       " 'приведу',\n",
       " 'приведя',\n",
       " 'привад',\n",
       " 'привод',\n",
       " 'присед',\n",
       " 'при ед',\n",
       " 'пр вед',\n",
       " 'при вед',\n",
       " 'привед')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[hypothesis: пр вед ватрушке в общемчтотелескапать score: 0.999347,\n",
       " hypothesis: пр вед ватрушке в общемчтотеле слазать score: 0.999336,\n",
       " hypothesis: пр вед ватрушке в общем шортеве скачать score: 0.999319,\n",
       " hypothesis: приведватрушке вобщемшоннебеслазать score: 0.998875,\n",
       " hypothesis: привед ватрушкам вобщем го тесеказать score: 0.998816,\n",
       " hypothesis: пр вед ватрушке в общем йо теес казать score: 0.998631,\n",
       " hypothesis: привед ватрушкам вобщемоте е слазать score: 0.997880,\n",
       " hypothesis: привед ват ушкаобщемшотесе скатать score: 0.997859,\n",
       " hypothesis: пр ведватрушкам вобщем иотеве слазать score: 0.997762,\n",
       " hypothesis: приведватрушке вобщемшоннебескапать score: 0.997581,\n",
       " hypothesis: приведватрушке вобщемшонзебе с казать score: 0.996866,\n",
       " hypothesis: пр вед ватрушкевобьем ош требе скакать score: 0.996045,\n",
       " hypothesis: пр вед ватрушке в общем йо теесказа ь score: 0.995384,\n",
       " hypothesis: привед ват ушкаобщем шло гебескачать score: 0.995212,\n",
       " hypothesis: приведватрушки вобьем отекеуказать score: 0.995044,\n",
       " hypothesis: пр ведватрушкевобьем цо те бе оказать score: 0.994771,\n",
       " hypothesis: пр ведватрушкам вобщемш.теке сказать score: 0.993304,\n",
       " hypothesis: приведватрушкивоющем нонебе скачать score: 0.992621,\n",
       " hypothesis: пр ведватрушкам вобщем шгебе скачать score: 0.992233,\n",
       " hypothesis: пр ведватрушкам вобщем шгебескачать score: 0.991786,\n",
       " hypothesis: пр ведватрушкам вобщем шов тхебе казать score: 0.991095,\n",
       " hypothesis: пр ведватрушкам вобщемш. фебе скапать score: 0.990781,\n",
       " hypothesis: привед ватрушкам вобщемо тезескакать score: 0.990553,\n",
       " hypothesis: привед ватрушкамвобьемшлокебе слазать score: 0.990100,\n",
       " hypothesis: пр ведватрушка вобьем что тешесказать score: 0.989401,\n",
       " hypothesis: привед ват ушкаобщемштзебесказать score: 0.988296,\n",
       " hypothesis: пр ведватрушка вобьемйо лебе скачать score: 0.987332,\n",
       " hypothesis: привед ватрушкамвобьемшостебя скапать score: 0.987101,\n",
       " hypothesis: пр ведватрушка вобьем хостебе оказать score: 0.986192,\n",
       " hypothesis: пр вед ватрушке в общемчто шебескатать score: 0.985198,\n",
       " hypothesis: пр вед ватрушкевобьемшвотеме с казать score: 0.984828,\n",
       " hypothesis: привед ват ушкаобщем ао тетеуказать score: 0.984366,\n",
       " hypothesis: привед ватрушкам вобщем готече сказать score: 0.984293,\n",
       " hypothesis: пр вед ватрушкевобьемшвотемеказать score: 0.984123,\n",
       " hypothesis: привед ватрушкам вобщем готечесмазать score: 0.983683,\n",
       " hypothesis: привед ват ушкавобьем штфебесказа ь score: 0.983538,\n",
       " hypothesis: приведватрушкевоющем до лебе скачать score: 0.982363,\n",
       " hypothesis: приведватрушкевоющемсо тете скапать score: 0.982352,\n",
       " hypothesis: пр вед ватрушкевобьемшво тезескатать score: 0.982220,\n",
       " hypothesis: привед ватрушкам вобщем шоу тубескакать score: 0.981847,\n",
       " hypothesis: приведватрушкевоющем до лебе казать score: 0.981807,\n",
       " hypothesis: пр вед ватрушке в общемто лебесказа ь score: 0.981693,\n",
       " hypothesis: приведватрушкевоющем шу себескачать score: 0.981345,\n",
       " hypothesis: пр ведватрушкевобьемшутезеказать score: 0.981049,\n",
       " hypothesis: пр ведватрушка вобьем хостебеоказать score: 0.979699,\n",
       " hypothesis: привед ват ушкаобщемшттенеоказать score: 0.979177,\n",
       " hypothesis: пр ведватрушкам вобщем ш ребе с казать score: 0.979152,\n",
       " hypothesis: привед ват ушкаобщем шок зебе скачать score: 0.979122,\n",
       " hypothesis: пр ведватрушкевобьем цо те бе скапать score: 0.978821,\n",
       " hypothesis: привед ват ушкаобщем ао тещескакать score: 0.978548,\n",
       " hypothesis: приведватрушкевоющемсотедесказа ь score: 0.977895,\n",
       " hypothesis: привед ват ушкаобщем ао теще оказать score: 0.977817,\n",
       " hypothesis: пр ведватрушкам вобщем иотевескачать score: 0.977607,\n",
       " hypothesis: приведватрушке вобщемшоннебе казать score: 0.976878,\n",
       " hypothesis: привед ват ушкаобщем шок зебеслазать score: 0.976672,\n",
       " hypothesis: приведватрушкивоющем ш о требеуказать score: 0.976536,\n",
       " hypothesis: пр ведватрушка вобьемйо лебеслазать score: 0.976253,\n",
       " hypothesis: пр вед ватрушкевобьемшвотеме скапать score: 0.976189,\n",
       " hypothesis: приведватрушке вобщем мотещесказать score: 0.975974,\n",
       " hypothesis: привед ватрушкам вобщем готе е сказа ь score: 0.975600,\n",
       " hypothesis: пр ведватрушкевобьемшут бе скакать score: 0.975190,\n",
       " hypothesis: приведватрушкивоющем ш о требескапать score: 0.975159,\n",
       " hypothesis: привед ватрушкамвобьемшостебясказа ь score: 0.975020,\n",
       " hypothesis: пр ведватрушке воющем шволебеуказать score: 0.974806,\n",
       " hypothesis: приведватрушкевоющемш озебе сказать score: 0.974525,\n",
       " hypothesis: пр ведватрушка вобьем хостебескакать score: 0.974399,\n",
       " hypothesis: приведватрушке вобщемшонзебе скапать score: 0.974063,\n",
       " hypothesis: пр ведватрушке воющем то лебе скапать score: 0.972900,\n",
       " hypothesis: привед ват ушкавобьемотекескатать score: 0.972790,\n",
       " hypothesis: привед ват ушкавобьемш тещескакать score: 0.972084,\n",
       " hypothesis: привед ват ушкавобьемш т бес казать score: 0.971905,\n",
       " hypothesis: пр вед ватрушке в общемчтотеле скачать score: 0.971758,\n",
       " hypothesis: приведватрушкевоющем шу тубесказа ь score: 0.971429,\n",
       " hypothesis: приведватрушкевоющем до лебе оказать score: 0.971137,\n",
       " hypothesis: приведватрушкевоющем до лебе смазать score: 0.971113,\n",
       " hypothesis: привед ватрушкамвоющем ош те е сказать score: 0.970913,\n",
       " hypothesis: привед ватрушкамвобьемшазебес казать score: 0.970857,\n",
       " hypothesis: пр ведватрушке воющем то лебесказать score: 0.970734,\n",
       " hypothesis: привед ватрушкам вобщем шоу тубе скапать score: 0.970510,\n",
       " hypothesis: пр ведватрушкам вобщемш. фебескатать score: 0.969893,\n",
       " hypothesis: привед ватрушкамвобьемшло шебесказа ь score: 0.969270,\n",
       " hypothesis: привед ват ушкаобщем шок зебе казать score: 0.969234,\n",
       " hypothesis: привед ватрушкам вобщем го тесе с казать score: 0.968794,\n",
       " hypothesis: пр вед ватрушке в общемтошебе с казать score: 0.968024,\n",
       " hypothesis: пр ведватрушка вобьемшоттебы смазать score: 0.967992,\n",
       " hypothesis: привед ват ушкавобьемотеке скакать score: 0.967819,\n",
       " hypothesis: привед ват ушкаобщемшозебеуказать score: 0.966968,\n",
       " hypothesis: пр ведватрушка вобьем что тешескатать score: 0.966411,\n",
       " hypothesis: привед ват ушкавобьемлоребе скатать score: 0.966367,\n",
       " hypothesis: приведватрушкевоющемшлозебесказа ь score: 0.965290,\n",
       " hypothesis: приведватрушкивоющем ш отебыуказать score: 0.964671,\n",
       " hypothesis: пр ведватрушка вобьем хостебе скатать score: 0.963408,\n",
       " hypothesis: приведватрушки вобьем отеке сказа ь score: 0.963375,\n",
       " hypothesis: приведватрушкевоющемцо течеказать score: 0.962488,\n",
       " hypothesis: привед ватрушкамвобьемшазебе слазать score: 0.961911,\n",
       " hypothesis: привед ватрушкамвобьемшлокебес казать score: 0.961618,\n",
       " hypothesis: пр ведватрушка вобьем хостебе смазать score: 0.961505,\n",
       " hypothesis: приведватрушке вобщемсосебескатать score: 0.961171,\n",
       " hypothesis: приведватрушке вобщем мотещесмазать score: 0.960850,\n",
       " hypothesis: привед ват ушкаобщемшозебескакать score: 0.960636]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sc.analyze_sentence(\"привед ватрушка вобщем шо тебе сказать\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "при вед ватрушке вобщем шовтребескапать 0.9999937537165716\n",
      "при ведватрушка в общемшоп тебескапать 0.9998266075892084\n",
      "приведяватрушкивобьемкотеле сказа ь 0.9994121022028675\n",
      "при вед ватрушкевобьем шовнебе скатать 0.999360361384877\n",
      "при ведватрушках вобьем шоптеше указать 0.9992974041991589\n",
      "при ведватрушках вобьемяостебеказать 0.9978808294514523\n",
      "при ведватрушкахвобьем шолебе скакать 0.9970061430406191\n",
      "приведя ватрушках общем шон теге скатать 0.996688087234212\n",
      "при ведватрушкавобьемао ребе смазать 0.9966866641873804\n",
      "при вед ватрушкам вобщемботебасказа ь 0.9945597773603589\n",
      "при ведватрушкавобьем шутеще сказа ь 0.9944513122869074\n",
      "приведяватрушкивобьемфо т бе сказать 0.9936121604780269\n",
      "при вед ватрушке вобщем шов теве скатать 0.9930758896178744\n",
      "при ведватрушкавобьемно тезе скакать 0.9923264826330239\n",
      "при ведват ушка общем котебауказать 0.9919261487977555\n",
      "приведя ватрушкахобщем шоктеве скатать 0.9913399328988822\n",
      "приведяватрушкивобьемфо т бе скакать 0.9910095721175272\n",
      "приведя ватрушках общемотенесказать 0.9906312989249826\n",
      "приведяватрушкивобьемкотелеоказать 0.990459578835193\n",
      "приведя ватрушках общем шон тегескакать 0.9879411843415012\n",
      "приведяватрушкивобьемфо т беоказать 0.987616857660873\n",
      "приведяватрушкивобьемфо т бе слазать 0.9866389740856902\n",
      "приведя ватрушкахобщем шоктевесказа ь 0.9864972781316719\n",
      "при вед ватрушкам вобщемдотюбеоказать 0.9862286381530571\n",
      "приведя ватрушках общем шонтеме скакать 0.9857550902404754\n",
      "при ведватрушкахвобьем шотеще указать 0.9849203006055876\n",
      "приведя ватрушках общем шонтемесказать 0.9843076658328648\n",
      "при ведват ушка в общемштзебе скачать 0.9842902134910156\n",
      "при ведватрушках вобьем сот беслазать 0.9834669699872703\n",
      "при ведватрушка в общемшоп тебесказа ь 0.9829998776745608\n",
      "при ведват ушка в общемшттеба скатать 0.9827780668347548\n",
      "приведя ватрушкахобщем ботеле казать 0.9825255396034535\n",
      "при ведват ушкаобщем шоп тебы скатать 0.9822019973033298\n",
      "приведя ватрушках общемотенескапать 0.9818240271013953\n",
      "приведя ватрушкахобщем шоктевеоказать 0.9816398364248269\n",
      "при ведват ушкаобщем яо теба с казать 0.9809968220258022\n",
      "при ведватрушках вобьем шоптеше с казать 0.9804740312903193\n",
      "при ведватрушка в общемкотребеказать 0.9799375860126819\n",
      "приведяватрушкивобьем бо тебы с казать 0.9791115625744543\n",
      "при вед ватрушке вобщемотече казать 0.9775908720911772\n",
      "при ведватрушках вобьем шопстебеслазать 0.9774478543393162\n",
      "при вед ватрушке вобщемшвотеле смазать 0.976456821795237\n",
      "при вед ватрушкам вобщем шо тепе скачать 0.9755933641711368\n",
      "при ведватрушкавобьемао ребеслазать 0.9752379820855838\n",
      "при ведватрушках вобьем шоптеше скатать 0.9742118355084413\n",
      "при ведватрушкахв общемсогебеуказать 0.9741444091178807\n",
      "приведя ватрушках общемошотетесказа ь 0.9740407216873992\n",
      "при ведват ушка в общемштзебеуказать 0.9732411003807808\n",
      "при ведват ушка в общемштзебе скакать 0.9725826116285718\n",
      "при ведватрушкахвобьем шолебе смазать 0.972319348741253\n",
      "при ведватрушках вобьемяостебе сказа ь 0.9718972627890442\n",
      "при ведват ушка общем ко зебе скакать 0.9712567718189357\n",
      "при ведват ушка общемш.тегескачать 0.9710839264400619\n",
      "при ведватрушкахв общемшортезе сказа ь 0.9704235282686593\n",
      "при вед ватрушкевобьем поте бе казать 0.9702831857268804\n",
      "при ведватрушка в общем ш.тебеуказать 0.9700567001322011\n",
      "при ведватрушкавобьем шутещес казать 0.9695865841591012\n",
      "приведяватрушкивобщем хо течесмазать 0.9685382503360088\n",
      "приведя ватрушкахобщем бо стебеоказать 0.9684405700107227\n",
      "при вед ватрушке вобщемшвозебе скакать 0.9670712056686395\n",
      "при ведват ушка в общемшттеде скакать 0.9661917074271756\n",
      "при вед ватрушкевобьем шов кебе с казать 0.9656853412418637\n",
      "при ведватрушках вобьем сот беоказать 0.9651596885142191\n",
      "приведя ватрушкахобщем шоктеве скапать 0.9644377959923331\n",
      "при ведватрушка в общем ро зебе сказать 0.9642535651057903\n",
      "приведяватрушкивобьемфо т бескачать 0.9641833331942672\n",
      "при ведватрушкахвоющемйотечеуказать 0.9633206289722164\n",
      "при ведватрушках вобьемяостебес казать 0.9629044464565283\n",
      "при ведват ушка в общемшлотеме скапать 0.9628821315197983\n",
      "при вед ватрушкам вобщем шотешес казать 0.9619805048896337\n",
      "при ведватрушкавобьем шу тебосказа ь 0.9608303454289361\n",
      "при ведват ушка общем ко зебе слазать 0.9595176566204768\n",
      "при вед ватрушкам вобщемдотребесмазать 0.9589777100511738\n",
      "приведяватрушкувобьем коте бескапать 0.9587833950353826\n",
      "при вед ватрушке вобщемшвотелесказа ь 0.9586697485741489\n",
      "приведя ватрушкахобщем шоктевес казать 0.9579725315593639\n",
      "приведяватрушкивобщем хо тече смазать 0.9578479896471443\n",
      "приведя ватрушках общем шонтемесмазать 0.957376975262496\n",
      "приведя ватрушках общемо тебасказа ь 0.9572299342623501\n",
      "при ведват ушка в общемшттедесказать 0.9565647961486314\n",
      "приведя ватрушках общем шонтемеоказать 0.9564728715219949\n",
      "приведя ватрушках общемотепе сказа ь 0.9558685786860902\n",
      "при ведватрушка в общем шоу теле сказать 0.9556201903263974\n",
      "при ведватрушкахвобьем шотеще смазать 0.9556038924683636\n",
      "при ведватрушка в общемкотребе скачать 0.9555871610606194\n",
      "при ведватрушкахвобьемло зебе смазать 0.9552690968194865\n",
      "приведя ватрушкахобщемешо теде оказать 0.9550745594246627\n",
      "при ведватрушкахвобьем шотещеказать 0.9549191452619478\n",
      "при вед ватрушкам вобщемботебаслазать 0.9547220383685024\n",
      "при ведватрушкахвобьем ошо тебя указать 0.9543317934985038\n",
      "при ведватрушкахв общем что тещеоказать 0.9542521259847578\n",
      "приведяватрушкивобьемфотибе указать 0.9539292763440301\n",
      "при ведватрушка в общемво требес казать 0.9538673416469711\n",
      "приведя ватрушках вобщемфо тенесмазать 0.9537688588515355\n",
      "при вед ватрушкам вобщем шо стебе сказать 0.9529766591961223\n",
      "при ведватрушка в общем ш.тебе казать 0.9523938576230101\n",
      "приведя ватрушках общемо теба оказать 0.9519113052230905\n",
      "приведя ватрушках вобщемфо тенеслазать 0.9518364216363536\n",
      "при вед ватрушкевобьем во теге скапать 0.9517068551407404\n",
      "при ведватрушках вобьемяостебе скачать 0.9513833193707749\n"
     ]
    }
   ],
   "source": [
    "for each_res in res:\n",
    "    print(each_res.text, each_res.score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3",
   "language": "python",
   "name": ".venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
