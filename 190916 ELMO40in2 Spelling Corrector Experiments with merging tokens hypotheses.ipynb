{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alx/Cloud/spell_corr/py_spelling_corrector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alx/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/alx/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to /home/alx/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/alx/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "/home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0918 17:18:13.682099 140152326514496 deprecation_wrapper.py:119] From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/bilm/training.py:21: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0918 17:18:13.682718 140152326514496 deprecation_wrapper.py:119] From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/bilm/training.py:21: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "from spelling_correction_models.elmo_40in_spelling_corrector.elmo_40in2_spelling_corrector import ELMO40in2SpellingCorrector\n",
    "from copy import deepcopy\n",
    "from spelling_correction_models.elmo_40in_spelling_corrector.helper_fns import *\n",
    "\n",
    "# def estimate_the_best_s_hypotheses(data_analysis_dict):\n",
    "#     hypotheses_hub = HypothesesHub()\n",
    "#     for current_token_idx, each_tok in enumerate(data_analysis_dict['tokenized_input_sentence']):\n",
    "#         if current_token_idx==0:\n",
    "#             # skip the first token which is <s>\n",
    "#             continue\n",
    "#         if current_token_idx==len(data_analysis_dict['tokenized_input_sentence'])-1:\n",
    "#             # skip the last token which is </s>\n",
    "#             continue\n",
    "#         print(each_tok)\n",
    "#         #  suffixes_hypotheses = data_analysis_dict['word_substitutions_candidates'].filter(start_idx=current_token_idx)\n",
    "#         suffixes_hypotheses = SCAnalysisDictManager.filter_by_start_index(\n",
    "#             data_anal_dict=data_analysis_dict, start_index=current_token_idx)\n",
    "#         print(\"suffixes_hypotheses\")\n",
    "#         print(suffixes_hypotheses)\n",
    "#         # suffixes hypotheses is a list of dicts with hypotheses that start at index: current_token_idx and finish at current_token_idx or later        \n",
    "#         # expect that each s_hypothesis in hub has finish index (pointer of the final index position).\n",
    "#         # Ex. suffixes_hypotheses: \n",
    "#         #         [{'tok_idx': 1,\n",
    "#         #            'top_k_candidates': [{'advantage': 0.0, 'token_str': 'мамо'},\n",
    "#         #             {'advantage': 0.8290032949621251, 'token_str': 'мама'},\n",
    "#         #             {'advantage': 0.0682681172786106, 'token_str': 'маме'},\n",
    "#         #             {'advantage': 1.4654415043774653, 'token_str': 'мало'},\n",
    "#         #             {'advantage': 0.5788053066965881, 'token_str': 'мимо'}]},\n",
    "\n",
    "#         #             {'tok_idx': (1, 3),\n",
    "#         #              'tok_idx_start': 2,\n",
    "#         #              'tok_idx_fin': 3,\n",
    "#         #              'top_k_candidates': [{'token_str': 'мыла',\n",
    "#         #                                    'token_merges': 1,\n",
    "#         #                                    'error_score': -4.0,\n",
    "#         #                                    'lm_scores_list': array([-4.99906474, -6.26263737]),\n",
    "#         #                                    'summated_base_scores': array([-13.19048357, -11.76141742]),\n",
    "#         #                                    'advantage': 9.690198885299584}]}\n",
    "#         #         ]\n",
    "        \n",
    "#         # TODO implement method:\n",
    "#         hypotheses_hub = hypotheses_hub.fork_for_suffixes_segment_hypotheses(suffixes_hypotheses)\n",
    "#         print(len(hypotheses_hub))\n",
    "#         # TODO prune hypotheses that has finish_index==current_token_idx, but dont prune hypotheses that are longer\n",
    "#     # TODO implement method:\n",
    "#     the_best_sentence_hypothesis = hypotheses_hub.find_top_k(top_k=1)\n",
    "#     return the_best_sentence_hypothesis\n",
    "\n",
    "# class SCAnalysisDictManager():\n",
    "#     \"\"\"\n",
    "#     Class which wraps operations for dict with sentence analysis of spelling corrector. \n",
    "    \n",
    "#     Example artifact:\n",
    "#     {'input_sentence': 'мамо мы ла рабу',\n",
    "#      'tokenized_input_sentence': ['<S>', 'мамо', 'мы', 'ла', 'рабу', '</S>'],\n",
    "#      'word_substitutions_candidates': [{'tok_idx': 0, 'top_k_candidates': []},\n",
    "#       {'tok_idx': 1,\n",
    "#        'top_k_candidates': [{'advantage': 0.0, 'token_str': 'мамо'},\n",
    "#         {'advantage': 0.8290032949621251, 'token_str': 'мама'},\n",
    "#         {'advantage': 0.0682681172786106, 'token_str': 'маме'},\n",
    "#         {'advantage': 1.4654415043774653, 'token_str': 'мало'},\n",
    "#         {'advantage': 0.5788053066965881, 'token_str': 'мимо'}]},\n",
    "#       {'tok_idx': 2, 'top_k_candidates': [{'advantage': 0.0, 'token_str': 'мы'}]},\n",
    "#       {'tok_idx': 3,\n",
    "#        'top_k_candidates': [{'advantage': 8.881784197001252e-16,\n",
    "#          'token_str': 'ла'},\n",
    "#         {'advantage': 1.1416171799843715, 'token_str': 'л'},\n",
    "#         {'advantage': 4.534746617501758, 'token_str': 'ли'},\n",
    "#         {'advantage': 0.2392642375027938, 'token_str': 'ло'},\n",
    "#         {'advantage': 1.5435339098199536, 'token_str': 'ль'},\n",
    "#         {'advantage': 0.6130232420520505, 'token_str': 'ля'},\n",
    "#         {'advantage': 0.5685809466324443, 'token_str': 'лаю'},\n",
    "#         {'advantage': 5.609125288265215, 'token_str': 'а'},\n",
    "#         {'advantage': 1.3843852873087856, 'token_str': 'ва'},\n",
    "#         {'advantage': 4.591302278044582, 'token_str': 'да'},\n",
    "#         {'advantage': 6.869433134510696, 'token_str': 'за'},\n",
    "#         {'advantage': 2.116203203263707, 'token_str': 'ка'},\n",
    "#         {'advantage': 0.894093864484022, 'token_str': 'ма'},\n",
    "#         {'advantage': 7.909878868209844, 'token_str': 'на'},\n",
    "#         {'advantage': 1.3567950485204125, 'token_str': 'та'},\n",
    "#         {'advantage': 0.8312294913850709, 'token_str': 'ела'},\n",
    "#         {'advantage': 2.2575124093097294, 'token_str': 'зла'},\n",
    "#         {'advantage': 2.1699851412306375, 'token_str': 'шла'}]},\n",
    "#       {'tok_idx': 4,\n",
    "#        'top_k_candidates': [{'advantage': 0.0, 'token_str': 'рабу'},\n",
    "#         {'advantage': 0.2985749735125065, 'token_str': 'раб'},\n",
    "#         {'advantage': 0.9318240256975585, 'token_str': 'раба'},\n",
    "#         {'advantage': 1.338874848056081, 'token_str': 'рабы'},\n",
    "#         {'advantage': 1.0092864240096588, 'token_str': 'разу'},\n",
    "#         {'advantage': 0.6805089544958989, 'token_str': 'рыбу'},\n",
    "#         {'advantage': 1.0757820984060213, 'token_str': 'бабу'}]},\n",
    "#       {'tok_idx': 5,\n",
    "#        'top_k_candidates': [{'advantage': 0.0, 'token_str': '</S>'}]},\n",
    "#       {'tok_idx': (2, 3),\n",
    "#        'tok_idx_start': 2,\n",
    "#        'tok_idx_fin': 3,\n",
    "#        'top_k_candidates': [{'token_str': 'мыла',\n",
    "#          'token_merges': 1,\n",
    "#          'error_score': -4.0,\n",
    "#          'lm_scores_list': array([-4.99906474, -6.26263737]),\n",
    "#          'summated_base_scores': array([-13.19048357, -11.76141742]),\n",
    "#          'advantage': 9.690198885299584}]}]}\n",
    "#     \"\"\"\n",
    "#     @staticmethod\n",
    "#     def filter_by_start_index(data_anal_dict, start_index):\n",
    "#         \"\"\"Given a dict with data analysis it filters out word spans substitution candidates which start at specific token index \n",
    "#         (integer measured in input sentence token space)\"\"\"\n",
    "#         assert \"word_substitutions_candidates\" in data_anal_dict\n",
    "#         # results list is a list of dicts of hypotheses sets for particular spans (1token spans and 2-token spans, AS-IS)\n",
    "#         results_list = []\n",
    "#         for each_dict_set_of_candidates in data_anal_dict['word_substitutions_candidates']:\n",
    "#             # here is a complex condition that iteratively checks that substitution candidates dict set starts at \n",
    "#             # specific token position. Then it filters out the best candidates subset from each set merges that sets and returns a result \n",
    "#             # of the query.\n",
    "#             # candidate set dict describes set of candidates which can substitute particular span it \n",
    "#             # may be 1token-1token substitution or may be Ntokens->1token substitution.\n",
    "#             # for the firsts tok_idx key is integer holding the start_index\n",
    "#             # for the latter tok_idx key is tuple holding the start_index and the last index\n",
    "                        \n",
    "#             if each_dict_set_of_candidates['tok_idx'] == start_index or \\\n",
    "#                 (isinstance(each_dict_set_of_candidates['tok_idx'], tuple) \\\n",
    "#                      and each_dict_set_of_candidates['tok_idx'][0]==start_index):\n",
    "#                 results_list.append(each_dict_set_of_candidates)\n",
    "        \n",
    "#         return results_list\n",
    "        \n",
    "# class SentenceHypothesis():\n",
    "#     def __init__(self, text):\n",
    "#         # TODO refactor clean code\n",
    "#         if text!=\"\":\n",
    "#             print(\"SentenceHypothesis must be init with empty string!\")\n",
    "#         self.text = \"\"\n",
    "# #         self.score = np.nan\n",
    "# #         self.lm_score = 0\n",
    "#         # score for error:\n",
    "# #         self.err_score = err_score\n",
    "# #         self.final_score = 0.0\n",
    "#         # token hypotheses of the sentence\n",
    "#         self.token_hypotheses = []\n",
    "        \n",
    "#         # index of the last token in hypothesis\n",
    "#         self.finish_idx = -1\n",
    "#         # -1 for empty hypothesis and tokens length for other\n",
    " \n",
    "#     def calc_advantage_score(self):\n",
    "#         adv_score = 0.0\n",
    "#         for each_token_hypothesis in self.token_hypotheses:\n",
    "#             adv_score+=each_token_hypothesis['advantage']\n",
    "#         return adv_score\n",
    "    \n",
    "#     def fork_for_each_suffix(self, suffixes_dicts_list):\n",
    "#         \"\"\"Given a list of suffixes strings it forks the current hypotheses into several\n",
    "#         hypotheses for each suffix.\n",
    "        \n",
    "#         : suffixes_dicts_list:\n",
    "#         Ex.:\n",
    "#         [\n",
    "#             {'tok_idx': 4,\n",
    "#                'top_k_candidates': [{'advantage': 0.0, 'token_str': 'рабу'},\n",
    "#                                     {'advantage': 0.2985749735125065, 'token_str': 'раб'},\n",
    "#                                     {'advantage': 0.9318240256975585, 'token_str': 'раба'},\n",
    "#                                     {'advantage': 1.338874848056081, 'token_str': 'рабы'},\n",
    "#                                     {'advantage': 1.0092864240096588, 'token_str': 'разу'},\n",
    "#                                     {'advantage': 0.6805089544958989, 'token_str': 'рыбу'},\n",
    "#                                     {'advantage': 1.0757820984060213, 'token_str': 'бабу'}]},\n",
    "#             {'tok_idx': (4, 5),\n",
    "#                'tok_idx_start': 4,\n",
    "#                'tok_idx_fin': 5,\n",
    "#                'top_k_candidates': [{'token_str': 'мыла',\n",
    "#                  'token_merges': 1,\n",
    "#                  'error_score': -4.0,\n",
    "#                  'lm_scores_list': array([-4.99906474, -6.26263737]),\n",
    "#                  'summated_base_scores': array([-13.19048357, -11.76141742]),\n",
    "#                  'advantage': 9.690198885299584}]}\n",
    "#          ]\n",
    "        \n",
    "#         \"\"\"\n",
    "#         hypotheses_list = []\n",
    "        \n",
    "#         for idx, each_suffix_dict in enumerate(suffixes_dicts_list):\n",
    "#             # iteration over list of dicts with segments-candidates. First dict is a dict with 1token-1token substitution candidates:\n",
    "#             if isinstance(each_suffix_dict['tok_idx'], int):\n",
    "#                 start_tok_idx = each_suffix_dict['tok_idx']\n",
    "#             elif isinstance(each_suffix_dict['tok_idx'], tuple):\n",
    "#                 start_tok_idx = each_suffix_dict['tok_idx'][0]\n",
    "#             else:\n",
    "#                 raise Exception(\"Wrong format! data: %s\" % each_suffix_dict)\n",
    "                \n",
    "#             for candidate_idx, each_candidate_dict in enumerate(each_suffix_dict['top_k_candidates']):\n",
    "#                 # TODO assert that each new candidate has lower advantage\n",
    "#                 new_sentence_hypothesis = deepcopy(self)\n",
    "#                 # ############################################################\n",
    "#                 # add a segment suffix to the sentence hypothesis:\n",
    "#                 new_sentence_hypothesis.text += \" \" + each_candidate_dict['token_str']\n",
    "#                 new_sentence_hypothesis.token_hypotheses.append(each_candidate_dict)\n",
    "                \n",
    "#                 # retrieve fin_tok_index from candidate span:\n",
    "#                 if isinstance(each_suffix_dict['tok_idx'], int):\n",
    "#                     fin_tok_idx = each_suffix_dict['tok_idx']\n",
    "#                 elif isinstance(each_suffix_dict['tok_idx'], tuple):\n",
    "#                     fin_tok_idx = each_suffix_dict['tok_idx'][1]\n",
    "                    \n",
    "#                 new_sentence_hypothesis.finish_idx = fin_tok_idx\n",
    "#                 # ############################################################\n",
    "            \n",
    "#                 hypotheses_list.append(new_sentence_hypothesis)\n",
    "\n",
    "#         return hypotheses_list\n",
    "\n",
    "#     def __repr__(self):        \n",
    "# #         if self.final_score!=0:\n",
    "\n",
    "# #             out_text = \" score: %f\" % self.final_score        \n",
    "# #         else:\n",
    "# #             out_text = \" score: %f\" % self.total_score()        \n",
    "#         advantage_score = self.calc_advantage_score()\n",
    "#         text = \"hypothesis: %s | advantage: %0.5f\" % (self.text, advantage_score)\n",
    "#         return text\n",
    "    \n",
    "# class HypothesesHub():\n",
    "#     def __init__(self):\n",
    "#         # init with null hypothesis:\n",
    "#         self.hypotheses = [SentenceHypothesis(\"\")]\n",
    "    \n",
    "#     def fork_for_suffixes_segment_hypotheses(self, segment_candidates_dicts_list):\n",
    "#         \"\"\"\n",
    "#         For each hypothesis in the hub it appends all candidates\n",
    "#         :param partial_candidates_dicts_list:\n",
    "#         Ex.: \n",
    "#         [\n",
    "#             {'tok_idx': 4,\n",
    "#                'top_k_candidates': [{'advantage': 0.0, 'token_str': 'рабу'},\n",
    "#                                     {'advantage': 0.2985749735125065, 'token_str': 'раб'},\n",
    "#                                     {'advantage': 0.9318240256975585, 'token_str': 'раба'},\n",
    "#                                     {'advantage': 1.338874848056081, 'token_str': 'рабы'},\n",
    "#                                     {'advantage': 1.0092864240096588, 'token_str': 'разу'},\n",
    "#                                     {'advantage': 0.6805089544958989, 'token_str': 'рыбу'},\n",
    "#                                     {'advantage': 1.0757820984060213, 'token_str': 'бабу'}]},\n",
    "#             {'tok_idx': (4, 5),\n",
    "#                'tok_idx_start': 4,\n",
    "#                'tok_idx_fin': 5,\n",
    "#                'top_k_candidates': [{'token_str': 'мыла',\n",
    "#                  'token_merges': 1,\n",
    "#                  'error_score': -4.0,\n",
    "#                  'lm_scores_list': array([-4.99906474, -6.26263737]),\n",
    "#                  'summated_base_scores': array([-13.19048357, -11.76141742]),\n",
    "#                  'advantage': 9.690198885299584}]}\n",
    "#          ]\n",
    "                                    \n",
    "        \n",
    "\n",
    "#         :return: updated self\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # validation that start indexes for candidates dicts are aligned\n",
    "#         assert isinstance(segment_candidates_dicts_list[0]['tok_idx'], int)\n",
    "#         suffixes_start_idx = segment_candidates_dicts_list[0]['tok_idx']\n",
    "#         if len(segment_candidates_dicts_list)>1:\n",
    "#             assert isinstance(segment_candidates_dicts_list[1]['tok_idx'], tuple)\n",
    "#             assert 'tok_idx_start' in segment_candidates_dicts_list[1]\n",
    "#             assert isinstance(segment_candidates_dicts_list[1]['tok_idx_start'], int)\n",
    "#             assert segment_candidates_dicts_list[1]['tok_idx_start']==suffixes_start_idx\n",
    "        \n",
    "#         new_hypotheses = []\n",
    "#         for each_s_hypothesis in self.hypotheses:\n",
    "#             if each_s_hypothesis.finish_idx < suffixes_start_idx:\n",
    "#                 # TODO implement method\n",
    "#                 print(\"each_s_hypothesis.finish_idx < suffixes_start_idx\")\n",
    "#                 hypos = each_s_hypothesis.fork_for_each_suffix(segment_candidates_dicts_list)\n",
    "#                 new_hypotheses += hypos\n",
    "#             else:\n",
    "#                 print(\"each_s_hypothesis.finish_idx > suffixes_start_idx\")\n",
    "#                 # we have a hypothesis that merged multiple tokens:\n",
    "#                 assert each_s_hypothesis.finish_idx >= suffixes_start_idx\n",
    "#                 # so add this hypothesis as is (without suffix appending):\n",
    "#                 new_hypotheses.append(each_s_hypothesis)\n",
    "            \n",
    "#         self.hypotheses = new_hypotheses\n",
    "#         return self\n",
    "    \n",
    "# #     def prune_hypotheses(self, top_k=100):\n",
    "# #         prunes_hypotheses to restricted amount\n",
    "    \n",
    "#     def find_top_k(self, top_k=-1):\n",
    "#         # TODO implement me\n",
    "#         return self.hypotheses\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.hypotheses)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init LetterCaser.\n",
      "Init language_model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-18 17:18:17.525 WARNING in 'tensorflow'['deprecation_wrapper'] at line 119: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/deeppavlov-0.1.6-py3.6.egg/deeppavlov/models/bidirectional_lms/elmo/utils.py:40: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "2019-09-18 17:18:17.526 WARNING in 'tensorflow'['deprecation_wrapper'] at line 119: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/deeppavlov-0.1.6-py3.6.egg/deeppavlov/models/bidirectional_lms/elmo/utils.py:41: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2019-09-18 17:18:17.541 WARNING in 'tensorflow'['deprecation_wrapper'] at line 119: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/deeppavlov-0.1.6-py3.6.egg/deeppavlov/models/bidirectional_lms/elmo/utils.py:43: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "2019-09-18 17:18:17.542 WARNING in 'tensorflow'['deprecation_wrapper'] at line 119: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/bilm/training.py:153: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2019-09-18 17:18:17.563 WARNING in 'tensorflow'['deprecation_wrapper'] at line 119: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/bilm/training.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "2019-09-18 17:18:17.589 WARNING in 'tensorflow'['deprecation_wrapper'] at line 119: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/bilm/training.py:211: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "2019-09-18 17:18:17.592 WARNING in 'tensorflow'['deprecation'] at line 506: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "2019-09-18 17:18:17.831 WARNING in 'tensorflow'['deprecation'] at line 323: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/bilm/training.py:372: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "2019-09-18 17:18:17.832 WARNING in 'tensorflow'['deprecation_wrapper'] at line 119: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/bilm/training.py:386: The name tf.nn.rnn_cell.ResidualWrapper is deprecated. Please use tf.compat.v1.nn.rnn_cell.ResidualWrapper instead.\n",
      "\n",
      "2019-09-18 17:18:17.832 WARNING in 'tensorflow'['deprecation'] at line 323: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/bilm/training.py:396: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "2019-09-18 17:18:17.856 WARNING in 'tensorflow'['deprecation'] at line 323: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/bilm/training.py:410: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "2019-09-18 17:18:18.16 WARNING in 'tensorflow'['deprecation'] at line 506: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "2019-09-18 17:18:18.23 WARNING in 'tensorflow'['deprecation'] at line 506: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SKIP CONNECTIONS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-18 17:18:18.526 WARNING in 'tensorflow'['deprecation_wrapper'] at line 119: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/deeppavlov-0.1.6-py3.6.egg/deeppavlov/models/bidirectional_lms/elmo/utils.py:52: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "2019-09-18 17:18:18.554 WARNING in 'tensorflow'['deprecation'] at line 323: From /home/alx/Cloud/dns/.venv3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2019-09-18 17:18:18.557 INFO in 'tensorflow'['saver'] at line 1280: Restoring parameters from /home/alx/Cloud/spell_corr/py_spelling_corrector/bidirectional_lms/elmo_ru_news/model.ckpt-1327437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init spelling_correction_candidates_generator.\n",
      "Initialization Completed.\n"
     ]
    }
   ],
   "source": [
    "elmo40in = ELMO40in2SpellingCorrector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Debugging of Analysis Dictionary Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = \"мамо мы ла рабу\"\n",
    "sentence = \"мама что нибудь скажет\"\n",
    "sentence = \"мама что нибуть скажет\"\n",
    "# sentence = \"очень классная тетка ктобы что не говорил\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variate merged hypothesis: мамачто\n",
      "candidates_list_for_token\n",
      "[(-4.0, 'мама то'), (-4.0, 'мам что'), (-4.0, 'мама что'), (-4.0, 'м мачто'), (-4.0, 'ма мачто'), (0, 'мамачто')]\n",
      "Skipping OOV hypothesis: мама то\n",
      "Skipping OOV hypothesis: мам что\n",
      "Skipping OOV hypothesis: мама что\n",
      "Skipping OOV hypothesis: м мачто\n",
      "Skipping OOV hypothesis: ма мачто\n",
      "Skipping OOV hypothesis: мамачто\n",
      "Variate merged hypothesis: чтонибудь\n",
      "candidates_list_for_token\n",
      "[(-4.0, 'что-нибудь'), (0, 'чтонибудь')]\n",
      "Merged TokenHypothesis is in dictionary!\n",
      "Merged TokenHypothesis is in dictionary!\n",
      "Variate merged hypothesis: нибудьскажет\n",
      "candidates_list_for_token\n",
      "[(0, 'нибудьскажет')]\n",
      "Skipping OOV hypothesis: нибудьскажет\n",
      "мама\n",
      "suffixes_hypotheses\n",
      "[{'tok_idx': 1, 'top_k_candidates': [{'advantage': 0.0, 'token_str': 'мама', 'zero_hypothesis': True, 'error_score': 0.0}]}]\n",
      "1\n",
      "что\n",
      "suffixes_hypotheses\n",
      "[{'tok_idx': 2, 'top_k_candidates': [{'advantage': 0.0, 'token_str': 'что', 'zero_hypothesis': True, 'error_score': 0.0}]}, {'tok_idx': (2, 3), 'tok_idx_start': 2, 'tok_idx_fin': 3, 'top_k_candidates': [{'token_str': 'что-нибудь', 'token_merges': 1, 'error_score': -6.0, 'lm_scores_list': array([-5.66669504, -4.59935437]), 'base_scores': array([[-4.03339502, -5.77316105],\n",
      "       [-4.03339502, -5.77316105]]), 'summated_base_scores': array([ -8.06679004, -11.5463221 ]), 'advantage': 5.347062736387848}]}, {'tok_idx': (2, 3), 'tok_idx_start': 2, 'tok_idx_fin': 3, 'top_k_candidates': [{'token_str': 'чтонибудь', 'token_merges': 1, 'error_score': -2.0, 'lm_scores_list': array([-7.37061967, -7.27755205]), 'base_scores': array([[-4.03339502, -5.77316105],\n",
      "       [-4.03339502, -5.77316105]]), 'summated_base_scores': array([ -8.06679004, -11.5463221 ]), 'advantage': 0.9649404276484468}]}]\n",
      "2\n",
      "нибудь\n",
      "suffixes_hypotheses\n",
      "[{'tok_idx': 3, 'top_k_candidates': [{'advantage': 8.881784197001252e-16, 'token_str': 'нибудь', 'zero_hypothesis': True, 'error_score': 0.0}]}]\n",
      "2\n",
      "скажет\n",
      "suffixes_hypotheses\n",
      "[{'tok_idx': 4, 'top_k_candidates': [{'advantage': 0.0, 'token_str': 'скажет', 'zero_hypothesis': True, 'error_score': 0.0}]}]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['мама', 'что-нибудь', 'скажет']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo40in.process_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мама что нибудь скажет'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_sentence = elmo40in.preprocess_sentence(sentence)\n",
    "elmo_data = elmo40in.lm.analyze_sentence(preprocessed_sentence)\n",
    "\n",
    "preprocessed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_sentence': 'мама что нибудь скажет',\n",
       " 'tokenized_input_sentence': ['<S>',\n",
       "  'мама',\n",
       "  'что',\n",
       "  'нибудь',\n",
       "  'скажет',\n",
       "  '</S>'],\n",
       " 'word_substitutions_candidates': [{'tok_idx': 0, 'top_k_candidates': []},\n",
       "  {'tok_idx': 1,\n",
       "   'top_k_candidates': [{'advantage': 8.881784197001252e-16,\n",
       "     'token_str': 'мама',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 2,\n",
       "   'top_k_candidates': [{'advantage': 4.440892098500626e-16,\n",
       "     'token_str': 'что',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 3,\n",
       "   'top_k_candidates': [{'advantage': 0.0,\n",
       "     'token_str': 'нибудь',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 4,\n",
       "   'top_k_candidates': [{'advantage': 0.0,\n",
       "     'token_str': 'скажет',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 5,\n",
       "   'top_k_candidates': [{'advantage': -8.881784197001252e-16,\n",
       "     'token_str': '</S>',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_dict = elmo40in.elmo_analysis_with_probable_candidates_reduction_dict_in_dict_out(\n",
    "    {'input_sentence': preprocessed_sentence,\n",
    "     'tokenized_input_sentence': elmo40in.lm.tokenize_sentence(preprocessed_sentence)}, \n",
    "    elmo_data)\n",
    "\n",
    "analysis_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variate merged hypothesis: мамачто\n",
      "candidates_list_for_token\n",
      "[(-4.0, 'мама то'), (-4.0, 'мам что'), (-4.0, 'мама что'), (-4.0, 'м мачто'), (-4.0, 'ма мачто'), (0, 'мамачто')]\n",
      "Skipping OOV hypothesis: мама то\n",
      "Skipping OOV hypothesis: мам что\n",
      "Skipping OOV hypothesis: мама что\n",
      "Skipping OOV hypothesis: м мачто\n",
      "Skipping OOV hypothesis: ма мачто\n",
      "Skipping OOV hypothesis: мамачто\n",
      "Variate merged hypothesis: чтонибудь\n",
      "candidates_list_for_token\n",
      "[(-4.0, 'что-нибудь'), (0, 'чтонибудь')]\n",
      "Merged TokenHypothesis is in dictionary!\n",
      "Merged TokenHypothesis is in dictionary!\n",
      "Variate merged hypothesis: нибудьскажет\n",
      "candidates_list_for_token\n",
      "[(0, 'нибудьскажет')]\n",
      "Skipping OOV hypothesis: нибудьскажет\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'tok_idx': (2, 3),\n",
       "  'tok_idx_start': 2,\n",
       "  'tok_idx_fin': 3,\n",
       "  'top_k_candidates': [{'token_str': 'что-нибудь',\n",
       "    'token_merges': 1,\n",
       "    'error_score': -6.0,\n",
       "    'lm_scores_list': array([-5.67669564, -2.8935005 ]),\n",
       "    'base_scores': array([[-4.09746087, -4.34933731],\n",
       "           [-4.09746087, -4.34933731]]),\n",
       "    'summated_base_scores': array([-8.19492174, -8.69867461]),\n",
       "    'advantage': 4.32340021605893}]},\n",
       " {'tok_idx': (2, 3),\n",
       "  'tok_idx_start': 2,\n",
       "  'tok_idx_fin': 3,\n",
       "  'top_k_candidates': [{'token_str': 'чтонибудь',\n",
       "    'token_merges': 1,\n",
       "    'error_score': -2.0,\n",
       "    'lm_scores_list': array([-7.36771827, -7.25287441]),\n",
       "    'base_scores': array([[-4.09746087, -4.34933731],\n",
       "           [-4.09746087, -4.34933731]]),\n",
       "    'summated_base_scores': array([-8.19492174, -8.69867461]),\n",
       "    'advantage': -1.7269963308896443}]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_tokens_hypotheses_dict = elmo40in.generate_Nto1_hypotheses(analysis_dict['tokenized_input_sentence'], elmo_data)\n",
    "merged_tokens_hypotheses_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_sentence': 'мама что нибудь скажет',\n",
       " 'tokenized_input_sentence': ['<S>',\n",
       "  'мама',\n",
       "  'что',\n",
       "  'нибудь',\n",
       "  'скажет',\n",
       "  '</S>'],\n",
       " 'word_substitutions_candidates': [{'tok_idx': 0, 'top_k_candidates': []},\n",
       "  {'tok_idx': 1,\n",
       "   'top_k_candidates': [{'advantage': 8.881784197001252e-16,\n",
       "     'token_str': 'мама',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 2,\n",
       "   'top_k_candidates': [{'advantage': 4.440892098500626e-16,\n",
       "     'token_str': 'что',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 3,\n",
       "   'top_k_candidates': [{'advantage': 0.0,\n",
       "     'token_str': 'нибудь',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 4,\n",
       "   'top_k_candidates': [{'advantage': 0.0,\n",
       "     'token_str': 'скажет',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 5,\n",
       "   'top_k_candidates': [{'advantage': -8.881784197001252e-16,\n",
       "     'token_str': '</S>',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': (2, 3),\n",
       "   'tok_idx_start': 2,\n",
       "   'tok_idx_fin': 3,\n",
       "   'top_k_candidates': [{'token_str': 'что-нибудь',\n",
       "     'token_merges': 1,\n",
       "     'error_score': -6.0,\n",
       "     'lm_scores_list': array([-5.67669564, -2.8935005 ]),\n",
       "     'base_scores': array([[-4.09746087, -4.34933731],\n",
       "            [-4.09746087, -4.34933731]]),\n",
       "     'summated_base_scores': array([-8.19492174, -8.69867461]),\n",
       "     'advantage': 4.32340021605893}]},\n",
       "  {'tok_idx': (2, 3),\n",
       "   'tok_idx_start': 2,\n",
       "   'tok_idx_fin': 3,\n",
       "   'top_k_candidates': [{'token_str': 'чтонибудь',\n",
       "     'token_merges': 1,\n",
       "     'error_score': -2.0,\n",
       "     'lm_scores_list': array([-7.36771827, -7.25287441]),\n",
       "     'base_scores': array([[-4.09746087, -4.34933731],\n",
       "            [-4.09746087, -4.34933731]]),\n",
       "     'summated_base_scores': array([-8.19492174, -8.69867461]),\n",
       "     'advantage': -1.7269963308896443}]}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_dict['word_substitutions_candidates'] += merged_tokens_hypotheses_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мама\n",
      "suffixes_hypotheses\n",
      "[{'tok_idx': 1, 'top_k_candidates': [{'advantage': 8.881784197001252e-16, 'token_str': 'мама', 'zero_hypothesis': True, 'error_score': 0.0}]}]\n",
      "suffixes_hypotheses after filtering\n",
      "[{'tok_idx': 1, 'top_k_candidates': [{'advantage': 8.881784197001252e-16, 'token_str': 'мама', 'zero_hypothesis': True, 'error_score': 0.0}]}]\n",
      "1\n",
      "что\n",
      "suffixes_hypotheses\n",
      "[{'tok_idx': 2, 'top_k_candidates': [{'advantage': 4.440892098500626e-16, 'token_str': 'что', 'zero_hypothesis': True, 'error_score': 0.0}]}, {'tok_idx': (2, 3), 'tok_idx_start': 2, 'tok_idx_fin': 3, 'top_k_candidates': [{'token_str': 'что-нибудь', 'token_merges': 1, 'error_score': -6.0, 'lm_scores_list': array([-5.67669564, -2.8935005 ]), 'base_scores': array([[-4.09746087, -4.34933731],\n",
      "       [-4.09746087, -4.34933731]]), 'summated_base_scores': array([-8.19492174, -8.69867461]), 'advantage': 4.32340021605893}]}, {'tok_idx': (2, 3), 'tok_idx_start': 2, 'tok_idx_fin': 3, 'top_k_candidates': [{'token_str': 'чтонибудь', 'token_merges': 1, 'error_score': -2.0, 'lm_scores_list': array([-7.36771827, -7.25287441]), 'base_scores': array([[-4.09746087, -4.34933731],\n",
      "       [-4.09746087, -4.34933731]]), 'summated_base_scores': array([-8.19492174, -8.69867461]), 'advantage': -1.7269963308896443}]}]\n",
      "suffixes_hypotheses after filtering\n",
      "[{'tok_idx': 2, 'top_k_candidates': [{'advantage': 4.440892098500626e-16, 'token_str': 'что', 'zero_hypothesis': True, 'error_score': 0.0}]}, {'tok_idx': (2, 3), 'tok_idx_start': 2, 'tok_idx_fin': 3, 'top_k_candidates': [{'token_str': 'что-нибудь', 'token_merges': 1, 'error_score': -6.0, 'lm_scores_list': array([-5.67669564, -2.8935005 ]), 'base_scores': array([[-4.09746087, -4.34933731],\n",
      "       [-4.09746087, -4.34933731]]), 'summated_base_scores': array([-8.19492174, -8.69867461]), 'advantage': 4.32340021605893}]}, {'tok_idx': (2, 3), 'tok_idx_start': 2, 'tok_idx_fin': 3, 'top_k_candidates': []}]\n",
      "2\n",
      "нибудь\n",
      "suffixes_hypotheses\n",
      "[{'tok_idx': 3, 'top_k_candidates': [{'advantage': 0.0, 'token_str': 'нибудь', 'zero_hypothesis': True, 'error_score': 0.0}]}]\n",
      "suffixes_hypotheses after filtering\n",
      "[{'tok_idx': 3, 'top_k_candidates': [{'advantage': 0.0, 'token_str': 'нибудь', 'zero_hypothesis': True, 'error_score': 0.0}]}]\n",
      "2\n",
      "скажет\n",
      "suffixes_hypotheses\n",
      "[{'tok_idx': 4, 'top_k_candidates': [{'advantage': 0.0, 'token_str': 'скажет', 'zero_hypothesis': True, 'error_score': 0.0}]}]\n",
      "suffixes_hypotheses after filtering\n",
      "[{'tok_idx': 4, 'top_k_candidates': [{'advantage': 0.0, 'token_str': 'скажет', 'zero_hypothesis': True, 'error_score': 0.0}]}]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[hypothesis:  мама что-нибудь скажет | advantage: 4.32340,\n",
       " hypothesis:  мама что нибудь скажет | advantage: 0.00000]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypos = estimate_the_best_s_hypotheses(data_analysis_dict=analysis_dict, min_advantage_treshold=1.0)\n",
    "hypos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' мама что-нибудь скажет'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypos[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluate_spelling_corrector\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALOG_DATA_PATH = 'data/dialog/'\n",
    "# Train data\n",
    "# TRAIN_ERRONEOUS_DATA = DIALOG_DATA_PATH + \"source_sents.txt\"\n",
    "# TRAIN_GOLDEN_DATA = DIALOG_DATA_PATH + \"corrected_sents.txt\"\n",
    "\n",
    "# Test data\n",
    "TEST_ERRONEOUS_DATA = DIALOG_DATA_PATH + \"test_sample_testset.txt\"\n",
    "TEST_GOLDEN_DATA = DIALOG_DATA_PATH + \"corr_sample_testset.txt\"\n",
    "\n",
    "\n",
    "# Clean train\n",
    "CLEAN_TRAIN_ERRONEOUS_DATA = DIALOG_DATA_PATH + \"train_input_sentences.txt\"\n",
    "CLEAN_TRAIN_GOLDEN_DATA = DIALOG_DATA_PATH + \"train_golden_sentences.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned train!\n",
    "with open(CLEAN_TRAIN_ERRONEOUS_DATA, 'r') as sents_file:\n",
    "    erroneous_lines = sents_file.readlines()\n",
    "    erroneous_lines = [line.lower().strip() for line in erroneous_lines]\n",
    "    \n",
    "with open(CLEAN_TRAIN_GOLDEN_DATA, 'r') as sents_file:\n",
    "    golden_lines = sents_file.readlines()\n",
    "    golden_lines = [line.lower().strip() for line in golden_lines]\n",
    "    \n",
    "    \n",
    "# calculate number of sentnences with the same token length in TEST dataset\n",
    "# with open(TEST_ERRONEOUS_DATA, 'r') as sents_file:\n",
    "with open(TEST_ERRONEOUS_DATA, 'r') as sents_file:\n",
    "    erroneous_lines_tst = sents_file.readlines()\n",
    "    erroneous_lines_tst = [line.lower().strip() for line in erroneous_lines_tst]\n",
    "    \n",
    "# with open(TEST_GOLDEN_DATA, 'r') as sents_file:\n",
    "with open(TEST_GOLDEN_DATA, 'r') as sents_file:\n",
    "    golden_lines_tst = sents_file.readlines()\n",
    "    golden_lines_tst = [line.lower().strip() for line in golden_lines_tst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare analysis dicts for sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'golden_sentence': 'очень классная тетка кто бы что ни говорил',\n",
      " 'input_sentence': 'она прямо бурлит у меня в крови тормошит какими-то '\n",
      "                   'советами смотрит на меня из глаз моей дочки что носит ее '\n",
      "                   'имя',\n",
      " 'tokenized_input_sentence': ['<S>',\n",
      "                              'она',\n",
      "                              'прямо',\n",
      "                              'бурлит',\n",
      "                              'у',\n",
      "                              'меня',\n",
      "                              'в',\n",
      "                              'крови',\n",
      "                              'тормошит',\n",
      "                              'какими-то',\n",
      "                              'советами',\n",
      "                              'смотрит',\n",
      "                              'на',\n",
      "                              'меня',\n",
      "                              'из',\n",
      "                              'глаз',\n",
      "                              'моей',\n",
      "                              'дочки',\n",
      "                              'что',\n",
      "                              'носит',\n",
      "                              'ее',\n",
      "                              'имя',\n",
      "                              '</S>'],\n",
      " 'word_substitutions_candidates': [{'tok_idx': 0, 'top_k_candidates': []},\n",
      "                                   {'tok_idx': 1,\n",
      "                                    'top_k_candidates': [{'advantage': 2.220446049250313e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'она',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 2,\n",
      "                                    'top_k_candidates': [{'advantage': -4.440892098500626e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'прямо',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 3,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'бурлит',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 4,\n",
      "                                    'top_k_candidates': [{'advantage': -4.440892098500626e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'у',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 5,\n",
      "                                    'top_k_candidates': [{'advantage': 1.1102230246251565e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'меня',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 6,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'в',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 7,\n",
      "                                    'top_k_candidates': [{'advantage': -8.881784197001252e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'крови',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 8,\n",
      "                                    'top_k_candidates': [{'advantage': 8.881784197001252e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'тормошит',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 9,\n",
      "                                    'top_k_candidates': [{'advantage': 4.440892098500626e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'какими-то',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 10,\n",
      "                                    'top_k_candidates': [{'advantage': 8.881784197001252e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'советами',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 11,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'смотрит',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 12,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'на',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 13,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'меня',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 14,\n",
      "                                    'top_k_candidates': [{'advantage': -8.881784197001252e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'из',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 15,\n",
      "                                    'top_k_candidates': [{'advantage': -8.881784197001252e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'глаз',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 16,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'моей',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 17,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'дочки',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 18,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'что',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 19,\n",
      "                                    'top_k_candidates': [{'advantage': -8.881784197001252e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'носит',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 20,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'ее',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 21,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'имя',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 22,\n",
      "                                    'top_k_candidates': [{'advantage': -8.881784197001252e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': '</S>',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': (3, 4),\n",
      "                                    'tok_idx_fin': 4,\n",
      "                                    'tok_idx_start': 3,\n",
      "                                    'top_k_candidates': [{'advantage': -7.337346680462325,\n",
      "                                                          'base_scores': array([[-2.57388758, -2.17581156],\n",
      "       [-2.57388758, -2.17581156]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-5.39901848, -7.43772648]),\n",
      "                                                          'summated_base_scores': array([-5.14777517, -4.35162312]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'бурлит'}]},\n",
      "                                   {'tok_idx': (3, 4),\n",
      "                                    'tok_idx_fin': 4,\n",
      "                                    'tok_idx_start': 3,\n",
      "                                    'top_k_candidates': [{'advantage': -11.172493331156524,\n",
      "                                                          'base_scores': array([[-2.57388758, -2.17581156],\n",
      "       [-2.57388758, -2.17581156]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-7.43387099, -9.23802063]),\n",
      "                                                          'summated_base_scores': array([-5.14777517, -4.35162312]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'бурлить'}]},\n",
      "                                   {'tok_idx': (3, 4),\n",
      "                                    'tok_idx_fin': 4,\n",
      "                                    'tok_idx_start': 3,\n",
      "                                    'top_k_candidates': [{'advantage': -13.286551926296266,\n",
      "                                                          'base_scores': array([[-2.57388758, -2.17581156],\n",
      "       [-2.57388758, -2.17581156]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([ -8.71534737, -10.07060284]),\n",
      "                                                          'summated_base_scores': array([-5.14777517, -4.35162312]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'буллиту'}]},\n",
      "                                   {'tok_idx': (4, 5),\n",
      "                                    'tok_idx_fin': 5,\n",
      "                                    'tok_idx_start': 4,\n",
      "                                    'top_k_candidates': [{'advantage': -16.80604360258691,\n",
      "                                                          'base_scores': array([[-1.15542179, -0.38049927],\n",
      "       [-1.15542179, -0.38049927]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-7.96942462, -7.90846111]),\n",
      "                                                          'summated_base_scores': array([-2.31084358, -0.76099854]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'умен'}]},\n",
      "                                   {'tok_idx': (4, 5),\n",
      "                                    'tok_idx_fin': 5,\n",
      "                                    'tok_idx_start': 4,\n",
      "                                    'top_k_candidates': [{'advantage': -17.321459291021004,\n",
      "                                                          'base_scores': array([[-1.15542179, -0.38049927],\n",
      "       [-1.15542179, -0.38049927]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-8.2171256 , -8.17617582]),\n",
      "                                                          'summated_base_scores': array([-2.31084358, -0.76099854]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'умея'}]},\n",
      "                                   {'tok_idx': (4, 5),\n",
      "                                    'tok_idx_fin': 5,\n",
      "                                    'tok_idx_start': 4,\n",
      "                                    'top_k_candidates': [{'advantage': -16.596088077502973,\n",
      "                                                          'base_scores': array([[-1.15542179, -0.38049927],\n",
      "       [-1.15542179, -0.38049927]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-7.48268972, -8.18524048]),\n",
      "                                                          'summated_base_scores': array([-2.31084358, -0.76099854]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'умения'}]},\n",
      "                                   {'tok_idx': (4, 5),\n",
      "                                    'tok_idx_fin': 5,\n",
      "                                    'tok_idx_start': 4,\n",
      "                                    'top_k_candidates': [{'advantage': -18.092683866172457,\n",
      "                                                          'base_scores': array([[-1.15542179, -0.38049927],\n",
      "       [-1.15542179, -0.38049927]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-7.62242424, -9.54210175]),\n",
      "                                                          'summated_base_scores': array([-2.31084358, -0.76099854]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'уменья'}]},\n",
      "                                   {'tok_idx': (4, 5),\n",
      "                                    'tok_idx_fin': 5,\n",
      "                                    'tok_idx_start': 4,\n",
      "                                    'top_k_candidates': [{'advantage': -5.657675623275833,\n",
      "                                                          'base_scores': array([[-1.15542179, -0.38049927],\n",
      "       [-1.15542179, -0.38049927]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-4.34901848, -0.38049927]),\n",
      "                                                          'summated_base_scores': array([-2.31084358, -0.76099854]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'меня'}]},\n",
      "                                   {'tok_idx': (5, 6),\n",
      "                                    'tok_idx_fin': 6,\n",
      "                                    'tok_idx_start': 5,\n",
      "                                    'top_k_candidates': [{'advantage': -3.909919231169129,\n",
      "                                                          'base_scores': array([[-0.51145954, -0.89320818],\n",
      "       [-0.51145954, -0.89320818]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-1.15542179, -1.56383288]),\n",
      "                                                          'summated_base_scores': array([-1.02291908, -1.78641636]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'меня'}]},\n",
      "                                   {'tok_idx': (5, 6),\n",
      "                                    'tok_idx_fin': 6,\n",
      "                                    'tok_idx_start': 5,\n",
      "                                    'top_k_candidates': [{'advantage': -19.150867087638716,\n",
      "                                                          'base_scores': array([[-0.51145954, -0.89320818],\n",
      "       [-0.51145954, -0.89320818]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-8.29692434, -9.66327818]),\n",
      "                                                          'summated_base_scores': array([-1.02291908, -1.78641636]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'меняй'}]},\n",
      "                                   {'tok_idx': (5, 6),\n",
      "                                    'tok_idx_fin': 6,\n",
      "                                    'tok_idx_start': 5,\n",
      "                                    'top_k_candidates': [{'advantage': -16.022669515347214,\n",
      "                                                          'base_scores': array([[-0.51145954, -0.89320818],\n",
      "       [-0.51145954, -0.89320818]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-7.45872547, -7.37327949]),\n",
      "                                                          'summated_base_scores': array([-1.02291908, -1.78641636]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'менял'}]},\n",
      "                                   {'tok_idx': (5, 6),\n",
      "                                    'tok_idx_fin': 6,\n",
      "                                    'tok_idx_start': 5,\n",
      "                                    'top_k_candidates': [{'advantage': -19.078971191879187,\n",
      "                                                          'base_scores': array([[-0.51145954, -0.89320818],\n",
      "       [-0.51145954, -0.89320818]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-8.8951089 , -8.99319772]),\n",
      "                                                          'summated_base_scores': array([-1.02291908, -1.78641636]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'меняю'}]},\n",
      "                                   {'tok_idx': (5, 6),\n",
      "                                    'tok_idx_fin': 6,\n",
      "                                    'tok_idx_start': 5,\n",
      "                                    'top_k_candidates': [{'advantage': -16.336357380197715,\n",
      "                                                          'base_scores': array([[-0.51145954, -0.89320818],\n",
      "       [-0.51145954, -0.89320818]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-8.08261999, -7.06307283]),\n",
      "                                                          'summated_base_scores': array([-1.02291908, -1.78641636]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'меняя'}]},\n",
      "                                   {'tok_idx': (6, 7),\n",
      "                                    'tok_idx_fin': 7,\n",
      "                                    'tok_idx_start': 6,\n",
      "                                    'top_k_candidates': [{'advantage': 2.1351152128221376,\n",
      "                                                          'base_scores': array([[-2.42815705, -5.65140713],\n",
      "       [-2.42815705, -5.65140713]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-4.37260602, -5.65140713]),\n",
      "                                                          'summated_base_scores': array([ -4.85631411, -11.30281425]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'крови'}]},\n",
      "                                   {'tok_idx': (19, 20),\n",
      "                                    'tok_idx_fin': 20,\n",
      "                                    'tok_idx_start': 19,\n",
      "                                    'top_k_candidates': [{'advantage': -5.550412962521614,\n",
      "                                                          'base_scores': array([[-1.34623645, -3.53036663],\n",
      "       [-1.34623645, -3.53036663]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-6.48694082, -4.81667829]),\n",
      "                                                          'summated_base_scores': array([-2.6924729 , -7.06073325]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'носите'}]},\n",
      "                                   {'tok_idx': (19, 20),\n",
      "                                    'tok_idx_fin': 20,\n",
      "                                    'tok_idx_start': 19,\n",
      "                                    'top_k_candidates': [{'advantage': -9.131964687316499,\n",
      "                                                          'base_scores': array([[-1.34623645, -3.53036663],\n",
      "       [-1.34623645, -3.53036663]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-8.49958149, -6.38558934]),\n",
      "                                                          'summated_base_scores': array([-2.6924729 , -7.06073325]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'носителе'}]}]}\n",
      "________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'golden_sentence': 'может выгоднее втулку продать и купить колесо в сборе',\n",
      " 'input_sentence': 'полчатся вот такие язычки',\n",
      " 'tokenized_input_sentence': ['<S>',\n",
      "                              'полчатся',\n",
      "                              'вот',\n",
      "                              'такие',\n",
      "                              'язычки',\n",
      "                              '</S>'],\n",
      " 'word_substitutions_candidates': [{'tok_idx': 0, 'top_k_candidates': []},\n",
      "                                   {'tok_idx': 1,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'полчатся',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 2,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'вот',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 3,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'такие',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 4,\n",
      "                                    'top_k_candidates': [{'advantage': -1.7763568394002505e-15,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'язычки',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 5,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': '</S>',\n",
      "                                                          'zero_hypothesis': True}]}]}\n",
      "________________________________________\n",
      "{'golden_sentence': 'довольно большая часть пришедших сходила с дорожек и '\n",
      "                    'усаживалась на траву',\n",
      " 'input_sentence': 'роспись была назначена на вторую половину дня поэтому '\n",
      "                   'время на прогулку и фотосессию было ограничено',\n",
      " 'tokenized_input_sentence': ['<S>',\n",
      "                              'роспись',\n",
      "                              'была',\n",
      "                              'назначена',\n",
      "                              'на',\n",
      "                              'вторую',\n",
      "                              'половину',\n",
      "                              'дня',\n",
      "                              'поэтому',\n",
      "                              'время',\n",
      "                              'на',\n",
      "                              'прогулку',\n",
      "                              'и',\n",
      "                              'фотосессию',\n",
      "                              'было',\n",
      "                              'ограничено',\n",
      "                              '</S>'],\n",
      " 'word_substitutions_candidates': [{'tok_idx': 0, 'top_k_candidates': []},\n",
      "                                   {'tok_idx': 1,\n",
      "                                    'top_k_candidates': [{'advantage': 8.881784197001252e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'роспись',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 2,\n",
      "                                    'top_k_candidates': [{'advantage': -5.551115123125783e-17,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'была',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 3,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'назначена',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 4,\n",
      "                                    'top_k_candidates': [{'advantage': 5.551115123125783e-17,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'на',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 5,\n",
      "                                    'top_k_candidates': [{'advantage': -1.6653345369377348e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'вторую',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 6,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'половину',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 7,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'дня',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 8,\n",
      "                                    'top_k_candidates': [{'advantage': 4.440892098500626e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'поэтому',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 9,\n",
      "                                    'top_k_candidates': [{'advantage': -2.220446049250313e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'время',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 10,\n",
      "                                    'top_k_candidates': [{'advantage': 5.551115123125783e-17,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'на',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 11,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'прогулку',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 12,\n",
      "                                    'top_k_candidates': [{'advantage': -2.220446049250313e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'и',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 13,\n",
      "                                    'top_k_candidates': [{'advantage': 8.881784197001252e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'фотосессию',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 14,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'было',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 15,\n",
      "                                    'top_k_candidates': [{'advantage': 0.0,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': 'ограничено',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': 16,\n",
      "                                    'top_k_candidates': [{'advantage': 8.881784197001252e-16,\n",
      "                                                          'error_score': 0.0,\n",
      "                                                          'token_str': '</S>',\n",
      "                                                          'zero_hypothesis': True}]},\n",
      "                                   {'tok_idx': (9, 10),\n",
      "                                    'tok_idx_fin': 10,\n",
      "                                    'tok_idx_start': 9,\n",
      "                                    'top_k_candidates': [{'advantage': -17.68931245009143,\n",
      "                                                          'base_scores': array([[-1.56822901, -0.25210671],\n",
      "       [-1.56822901, -0.25210671]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([ -6.73744758, -10.59253631]),\n",
      "                                                          'summated_base_scores': array([-3.13645802, -0.50421342]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'времянка'}]},\n",
      "                                   {'tok_idx': (9, 10),\n",
      "                                    'tok_idx_fin': 10,\n",
      "                                    'tok_idx_start': 9,\n",
      "                                    'top_k_candidates': [{'advantage': -12.505308057513854,\n",
      "                                                          'base_scores': array([[-1.56822901, -0.25210671],\n",
      "       [-1.56822901, -0.25210671]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-5.31060802, -6.83537148]),\n",
      "                                                          'summated_base_scores': array([-3.13645802, -0.50421342]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'времена'}]},\n",
      "                                   {'tok_idx': (11, 12),\n",
      "                                    'tok_idx_fin': 12,\n",
      "                                    'tok_idx_start': 11,\n",
      "                                    'top_k_candidates': [{'advantage': -4.9250097099141215,\n",
      "                                                          'base_scores': array([[-1.72322874, -1.94355655],\n",
      "       [-1.72322874, -1.94355655]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-2.89948369, -5.3590966 ]),\n",
      "                                                          'summated_base_scores': array([-3.44645748, -3.8871131 ]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'прогулку'}]},\n",
      "                                   {'tok_idx': (11, 12),\n",
      "                                    'tok_idx_fin': 12,\n",
      "                                    'tok_idx_start': 11,\n",
      "                                    'top_k_candidates': [{'advantage': -5.241961218462086,\n",
      "                                                          'base_scores': array([[-1.72322874, -1.94355655],\n",
      "       [-1.72322874, -1.94355655]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-2.75272681, -5.82280498]),\n",
      "                                                          'summated_base_scores': array([-3.44645748, -3.8871131 ]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'прогулки'}]},\n",
      "                                   {'tok_idx': (12, 13),\n",
      "                                    'tok_idx_fin': 13,\n",
      "                                    'tok_idx_start': 12,\n",
      "                                    'top_k_candidates': [{'advantage': 0.4467571233616603,\n",
      "                                                          'base_scores': array([[-2.76005049, -6.34886345],\n",
      "       [-2.76005049, -6.34886345]]),\n",
      "                                                          'error_score': -6.0,\n",
      "                                                          'lm_scores_list': array([-7.42220732, -6.34886345]),\n",
      "                                                          'summated_base_scores': array([ -5.52010099, -12.69772691]),\n",
      "                                                          'token_merges': 1,\n",
      "                                                          'token_str': 'фотосессию'}]}]}\n",
      "________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loop over sentences that has the same number of tokens as in correct answer\n",
    "hypotheses = []\n",
    "filtered_erroneous_lines = []\n",
    "filtered_golden_lines = []\n",
    "start_dt = dt.datetime.now()\n",
    "results_data = []\n",
    "# TRAIN dataset:\n",
    "input_sentences = erroneous_lines\n",
    "etalon_sentences = golden_lines\n",
    "\n",
    "# # TEST dataset:\n",
    "# input_sentences = erroneous_lines_tst\n",
    "# etalon_sentences = golden_lines_tst\n",
    "\n",
    "for idx, each_error_line in enumerate(input_sentences[10:30]):\n",
    "#     if idx<3:continue\n",
    "\n",
    "    analysis_dict = elmo40in.prepare_analysis_dict_for_sentence(each_error_line)\n",
    "\n",
    "    analysis_dict['golden_sentence'] = etalon_sentences[idx]\n",
    "    pprint.pprint(analysis_dict)\n",
    "    results_data.append(analysis_dict)\n",
    "    print(\"________________________________________\")\n",
    "#     if idx>13:\n",
    "#         break\n",
    "fin_dt = dt.datetime.now()\n",
    "print(\"Total time for inference:\")\n",
    "print(fin_dt-start_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Grid Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets evaluate fixes model\n",
    "# 1. lets produce famili of fixers\n",
    "# max_num_fixes_params = (1,2,3,4,5)\n",
    "# fix_treshold_params = \n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "param_grid = {\n",
    "#     'max_num_fixes': np.arange(1, 6), \n",
    "    'min_advantage_treshold': np.linspace(0.1, 8.0, 10)}\n",
    "parameters_grid_list = list(ParameterGrid(param_grid))\n",
    "print(list(ParameterGrid(param_grid)))\n",
    "\n",
    "# fixes_maker(results_data[idx], max_num_fixes=5, fix_treshold=5, remove_s=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actually make fixes for particular SpellChecker Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_sentence': 'довольно большая часть пришедших сходила с дорожек и усаживалась на траву',\n",
       " 'tokenized_input_sentence': ['<S>',\n",
       "  'довольно',\n",
       "  'большая',\n",
       "  'часть',\n",
       "  'пришедших',\n",
       "  'сходила',\n",
       "  'с',\n",
       "  'дорожек',\n",
       "  'и',\n",
       "  'усаживалась',\n",
       "  'на',\n",
       "  'траву',\n",
       "  '</S>'],\n",
       " 'word_substitutions_candidates': [{'tok_idx': 0, 'top_k_candidates': []},\n",
       "  {'tok_idx': 1,\n",
       "   'top_k_candidates': [{'advantage': 8.881784197001252e-16,\n",
       "     'token_str': 'довольно',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 2,\n",
       "   'top_k_candidates': [{'advantage': 2.220446049250313e-16,\n",
       "     'token_str': 'большая',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 3,\n",
       "   'top_k_candidates': [{'advantage': 1.1102230246251565e-16,\n",
       "     'token_str': 'часть',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 4,\n",
       "   'top_k_candidates': [{'advantage': 8.881784197001252e-16,\n",
       "     'token_str': 'пришедших',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 5,\n",
       "   'top_k_candidates': [{'advantage': -2.220446049250313e-16,\n",
       "     'token_str': 'сходила',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 6,\n",
       "   'top_k_candidates': [{'advantage': 1.1102230246251565e-16,\n",
       "     'token_str': 'с',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 7,\n",
       "   'top_k_candidates': [{'advantage': 0.0,\n",
       "     'token_str': 'дорожек',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 8,\n",
       "   'top_k_candidates': [{'advantage': -1.1102230246251565e-16,\n",
       "     'token_str': 'и',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 9,\n",
       "   'top_k_candidates': [{'advantage': -8.881784197001252e-16,\n",
       "     'token_str': 'усаживалась',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 10,\n",
       "   'top_k_candidates': [{'advantage': -2.220446049250313e-16,\n",
       "     'token_str': 'на',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 11,\n",
       "   'top_k_candidates': [{'advantage': 0.0,\n",
       "     'token_str': 'траву',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': 12,\n",
       "   'top_k_candidates': [{'advantage': -8.881784197001252e-16,\n",
       "     'token_str': '</S>',\n",
       "     'zero_hypothesis': True,\n",
       "     'error_score': 0.0}]},\n",
       "  {'tok_idx': (5, 6),\n",
       "   'tok_idx_start': 5,\n",
       "   'tok_idx_fin': 6,\n",
       "   'top_k_candidates': [{'token_str': 'сходила',\n",
       "     'token_merges': 1,\n",
       "     'error_score': -6.0,\n",
       "     'lm_scores_list': array([-4.81609631, -6.16883221]),\n",
       "     'base_scores': array([[-0.51637928, -0.84334215],\n",
       "            [-0.51637928, -0.84334215]]),\n",
       "     'summated_base_scores': array([-1.03275855, -1.6866843 ]),\n",
       "     'advantage': -12.265485676353045}]},\n",
       "  {'tok_idx': (5, 6),\n",
       "   'tok_idx_start': 5,\n",
       "   'tok_idx_fin': 6,\n",
       "   'top_k_candidates': [{'token_str': 'сходилась',\n",
       "     'token_merges': 1,\n",
       "     'error_score': -6.0,\n",
       "     'lm_scores_list': array([-6.62185715, -5.99964732]),\n",
       "     'base_scores': array([[-0.51637928, -0.84334215],\n",
       "            [-0.51637928, -0.84334215]]),\n",
       "     'summated_base_scores': array([-1.03275855, -1.6866843 ]),\n",
       "     'advantage': -13.90206161438844}]},\n",
       "  {'tok_idx': (6, 7),\n",
       "   'tok_idx_start': 6,\n",
       "   'tok_idx_fin': 7,\n",
       "   'top_k_candidates': [{'token_str': 'дорожек',\n",
       "     'token_merges': 1,\n",
       "     'error_score': -6.0,\n",
       "     'lm_scores_list': array([-8.28748858, -5.36024817]),\n",
       "     'base_scores': array([[-4.12723669, -5.36024817],\n",
       "            [-4.12723669, -5.36024817]]),\n",
       "     'summated_base_scores': array([ -8.25447337, -10.72049634]),\n",
       "     'advantage': 1.327232965197119}]},\n",
       "  {'tok_idx': (7, 8),\n",
       "   'tok_idx_start': 7,\n",
       "   'tok_idx_fin': 8,\n",
       "   'top_k_candidates': [{'token_str': 'дорожек',\n",
       "     'token_merges': 1,\n",
       "     'error_score': -6.0,\n",
       "     'lm_scores_list': array([-4.12723669, -5.87710216]),\n",
       "     'base_scores': array([[-0.78221465, -0.88608534],\n",
       "            [-0.78221465, -0.88608534]]),\n",
       "     'summated_base_scores': array([-1.5644293 , -1.77217068]),\n",
       "     'advantage': -10.667738867207573}]},\n",
       "  {'tok_idx': (7, 8),\n",
       "   'tok_idx_start': 7,\n",
       "   'tok_idx_fin': 8,\n",
       "   'top_k_candidates': [{'token_str': 'дорожки',\n",
       "     'token_merges': 1,\n",
       "     'error_score': -6.0,\n",
       "     'lm_scores_list': array([-3.74727626, -5.29278091]),\n",
       "     'base_scores': array([[-0.78221465, -0.88608534],\n",
       "            [-0.78221465, -0.88608534]]),\n",
       "     'summated_base_scores': array([-1.5644293 , -1.77217068]),\n",
       "     'advantage': -9.703457188964142}]},\n",
       "  {'tok_idx': (8, 9),\n",
       "   'tok_idx_start': 8,\n",
       "   'tok_idx_fin': 9,\n",
       "   'top_k_candidates': [{'token_str': 'усаживалась',\n",
       "     'token_merges': 1,\n",
       "     'error_score': -6.0,\n",
       "     'lm_scores_list': array([-6.58733356, -5.38584747]),\n",
       "     'base_scores': array([[-4.83433044, -5.38584747],\n",
       "            [-4.83433044, -5.38584747]]),\n",
       "     'summated_base_scores': array([ -9.66866088, -10.77169494]),\n",
       "     'advantage': 4.467174788418491}]}],\n",
       " 'golden_sentence': 'довольно большая часть пришедших сходила с дорожек и усаживалась на траву'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "довольно\n",
      "большая\n",
      "часть\n",
      "пришедших\n",
      "сходила\n",
      "с\n",
      "дорожек\n",
      "и\n",
      "усаживалась\n",
      "на\n",
      "траву\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'довольно большая часть пришедших сходиладорожекусаживалась на траву'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo40in.make_fixes(results_data[2], min_advantage_treshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential method for TRAIN dataset\n",
    "# loop over sentences that has the same number of tokens as in correct answer\n",
    "hypotheses = [[] for each_ in range(len(parameters_grid_list))]\n",
    "filtered_erroneous_lines = []\n",
    "filtered_golden_lines = []\n",
    "\n",
    "for sent_idx, each_data in enumerate(results_data):\n",
    "    for estimator_idx, each_estimator_param in enumerate(parameters_grid_list):\n",
    "        print(\".\")\n",
    "        print(each_estimator_param)\n",
    "        sentence_hypothesis = elmo40in.make_fixes(each_data, **each_estimator_param)\n",
    "        hypotheses[estimator_idx].append(sentence_hypothesis)\n",
    "    filtered_erroneous_lines.append(each_data['input_sentence'])\n",
    "    filtered_golden_lines.append(each_data['golden_sentence'])\n",
    "\n",
    "# evaluate each estimator:\n",
    "print(\"!!!!!!!!!!\")\n",
    "for estimator_idx, each_estimator_param in enumerate(parameters_grid_list):\n",
    "    try:\n",
    "        results = evaluate_spelling_corrector(filtered_erroneous_lines, \n",
    "                                              filtered_golden_lines, \n",
    "                                              hypotheses[estimator_idx])\n",
    "        print(estimator_idx)\n",
    "        print(each_estimator_param)\n",
    "        print(\"f1:\")\n",
    "        print(results['f_measure'])\n",
    "        print(\"precision:\")\n",
    "        print(results['precision'])\n",
    "        print(\"_____\")\n",
    "    except Exception as e:\n",
    "        print(\"Zero precision\")\n",
    "        pass\n",
    "# pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.89935879, -6.68768751, -8.26770615, -8.44233911, -6.12489386,\n",
       "        -5.66360093, -7.97351025, -8.19241068, -7.67558967, -7.89791163],\n",
       "       [-6.14079886, -7.52041743, -8.23220287, -7.93148408, -7.7780586 ,\n",
       "        -6.86853707, -6.82381484, -8.01061398, -7.75469577, -9.07290786]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate score of the merged token\n",
    "# {'tok_idx': (2, 3),\n",
    "#    'tok_idx_start': 2,\n",
    "#    'tok_idx_fin': 3,\n",
    "#    'top_k_candidates': [{'token_str': 'мыла',\n",
    "#      'token_merges': 1,\n",
    "#      'error_score': -4.0}]}]}\n",
    "\n",
    "np.log10(elmo_data[1, :, 49657:49667])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "в_индкс, неизв = elmo40in.lm.get_word_idx_or_unk(\"мыла\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3",
   "language": "python",
   "name": ".venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
