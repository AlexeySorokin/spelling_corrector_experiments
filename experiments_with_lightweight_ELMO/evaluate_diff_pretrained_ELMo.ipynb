{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>и вобщем-то все понятно на фоне слухов застави...</td>\n",
       "      <td>и в общем-то все понятно на фоне слухов застав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>но всему есть придел</td>\n",
       "      <td>но всему есть предел</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>у нас в доме оччень много застекленных вертика...</td>\n",
       "      <td>у нас в доме очень много застекленных вертикал...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "2005  и вобщем-то все понятно на фоне слухов застави...   \n",
       "2006                               но всему есть придел   \n",
       "2007  у нас в доме оччень много застекленных вертика...   \n",
       "\n",
       "                                                   true  \n",
       "2005  и в общем-то все понятно на фоне слухов застав...  \n",
       "2006                               но всему есть предел  \n",
       "2007  у нас в доме очень много застекленных вертикал...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('dialog16/dialog_testset.txt', 'r') as f:\n",
    "    input_texts = f.readlines()\n",
    "    input_texts = [i[:-1] for i in input_texts if i != '\\n']\n",
    "    \n",
    "with open('dialog16/true_dialog_testset.txt', 'r') as f:\n",
    "    true_texts = f.readlines()\n",
    "    true_texts = [i[:-1] for i in true_texts if i != '\\n']\n",
    "\n",
    "data = pd.DataFrame(data=zip(input_texts, true_texts), columns=['source', 'true'])\n",
    "print(len(data))\n",
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>true</th>\n",
       "      <th>tokenized_source</th>\n",
       "      <th>tokenized_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>есть у вас оформленый и подписаный мною заказ</td>\n",
       "      <td>есть у вас оформленный и подписанный мною заказ</td>\n",
       "      <td>[есть, у, вас, оформленый, и, подписаный, мною...</td>\n",
       "      <td>[есть, у, вас, оформленный, и, подписанный, мн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>вот в инете откапал такую интеерсную статейку ...</td>\n",
       "      <td>вот в инете откопал такую интересную статейку ...</td>\n",
       "      <td>[вот, в, инете, откапал, такую, интеерсную, ст...</td>\n",
       "      <td>[вот, в, инете, откопал, такую, интересную, ст...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0      есть у вас оформленый и подписаный мною заказ   \n",
       "1  вот в инете откапал такую интеерсную статейку ...   \n",
       "\n",
       "                                                true  \\\n",
       "0    есть у вас оформленный и подписанный мною заказ   \n",
       "1  вот в инете откопал такую интересную статейку ...   \n",
       "\n",
       "                                    tokenized_source  \\\n",
       "0  [есть, у, вас, оформленый, и, подписаный, мною...   \n",
       "1  [вот, в, инете, откапал, такую, интеерсную, ст...   \n",
       "\n",
       "                                      tokenized_true  \n",
       "0  [есть, у, вас, оформленный, и, подписанный, мн...  \n",
       "1  [вот, в, инете, откопал, такую, интересную, ст...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokenized_source'] = [text.strip().split() for text in data['source']]\n",
    "data['tokenized_true'] = [text.strip().split() for text in data['true']]\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standart ELMo (5 gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/azat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/azat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/azat/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/azat/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:21: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:21: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ELMO_inference import ELMOLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/azat/Programs/spellchecker_models/shared_git/spelling_corrector_experiments/src/deeppavlov/deeppavlov/models/bidirectional_lms/elmo/utils.py:38: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/Programs/spellchecker_models/shared_git/spelling_corrector_experiments/src/deeppavlov/deeppavlov/models/bidirectional_lms/elmo/utils.py:39: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/Programs/spellchecker_models/shared_git/spelling_corrector_experiments/src/deeppavlov/deeppavlov/models/bidirectional_lms/elmo/utils.py:41: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:153: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:211: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "USING SKIP CONNECTIONS\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:372: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:386: The name tf.nn.rnn_cell.ResidualWrapper is deprecated. Please use tf.compat.v1.nn.rnn_cell.ResidualWrapper instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:396: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:410: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/azat/Programs/spellchecker_models/shared_git/spelling_corrector_experiments/src/deeppavlov/deeppavlov/models/bidirectional_lms/elmo/utils.py:50: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/azat/.deeppavlov/downloads/embeddings/elmo_ru_news/model.ckpt-1327437\n"
     ]
    }
   ],
   "source": [
    "standart_elmo = ELMOLM('/home/azat/.deeppavlov/downloads/embeddings/elmo_ru_news',\n",
    "                       './ru_elmo_voc_scores_by_kenlm.json', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [1:04:25, 15.80s/it]\n",
      "201it [1:04:31, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 45min 28s, sys: 24min 21s, total: 2h 9min 49s\n",
      "Wall time: 2h 8min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "source_likelihood = standart_elmo.estimate_likelihood_batch(data['tokenized_source'], batch_size=10)\n",
    "true_likelihood = standart_elmo.estimate_likelihood_batch(data['tokenized_true'], batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['scores_true'] = true_likelihood\n",
    "data['scores_source'] = source_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./answers_basic_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7559760956175299"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = data['scores_true'] > data['scores_source']\n",
    "sum(ans) / len(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standart ELMo (5 gb) one track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/azat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/azat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/azat/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/azat/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:21: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:21: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ELMO_inference import ELMO_LM_one_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/azat/Programs/spellchecker_models/shared_git/spelling_corrector_experiments/src/deeppavlov/deeppavlov/models/bidirectional_lms/elmo/utils.py:38: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/Programs/spellchecker_models/shared_git/spelling_corrector_experiments/src/deeppavlov/deeppavlov/models/bidirectional_lms/elmo/utils.py:39: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/Programs/spellchecker_models/shared_git/spelling_corrector_experiments/src/deeppavlov/deeppavlov/models/bidirectional_lms/elmo/utils.py:41: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:153: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:211: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "USING SKIP CONNECTIONS\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:372: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:386: The name tf.nn.rnn_cell.ResidualWrapper is deprecated. Please use tf.compat.v1.nn.rnn_cell.ResidualWrapper instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:396: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/bilm/training.py:410: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/azat/Programs/spellchecker_models/shared_git/spelling_corrector_experiments/src/deeppavlov/deeppavlov/models/bidirectional_lms/elmo/utils.py:50: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/azat/.deeppavlov/downloads/embeddings/elmo_ru_news/model.ckpt-1327437\n"
     ]
    }
   ],
   "source": [
    "elmo_one_track = ELMO_LM_one_track('/home/azat/.deeppavlov/downloads/embeddings/elmo_ru_news',\n",
    "                       './ru_elmo_voc_scores_by_kenlm.json', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consider hyps with the same size as source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_source = data['tokenized_source'].apply(lambda x: len(x))\n",
    "length_true = data['tokenized_true'].apply(lambda x: len(x))\n",
    "same_size = data[length_source == length_true]\n",
    "len(same_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [52:56, 17.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43min 21s, sys: 9min 55s, total: 53min 17s\n",
      "Wall time: 52min 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hyps = list(zip(same_size['tokenized_source'], same_size['tokenized_true']))\n",
    "likelihood = elmo_one_track.estimate_likelihood_batch(input_batch=same_size['tokenized_source'],\n",
    "                                                      hyp_batch=hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/azat/anaconda3/envs/spell/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "same_size['source_likelihood'] =[i[0] for i in likelihood]\n",
    "same_size['true_likelihood'] =[i[1] for i in likelihood]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47023809523809523"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = same_size.source_likelihood < same_size.true_likelihood\n",
    "sum(ans) / len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
