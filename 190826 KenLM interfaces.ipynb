{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 Neural Networks and Deep Learning lab, MIPT\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import kenlm\n",
    "\n",
    "from deeppavlov.core.commands.utils import expand_path\n",
    "from deeppavlov.core.common.registry import register\n",
    "from deeppavlov.core.models.component import Component\n",
    "from deeppavlov.core.common.log import get_logger\n",
    "\n",
    "\n",
    "class KenlmElector(Component):\n",
    "    \"\"\"Component that chooses a candidate with the highest product of base and language model probabilities\n",
    "\n",
    "    Args:\n",
    "         load_path: path to the kenlm model file\n",
    "         beam_size: beam size for highest probability search\n",
    "\n",
    "    Attributes:\n",
    "        lm: kenlm object\n",
    "        beam_size: beam size for highest probability search\n",
    "    \"\"\"\n",
    "    def __init__(self, load_path: Path, beam_size: int=4, *args, **kwargs):\n",
    "        self.lm = kenlm.Model(str(expand_path(load_path)))\n",
    "        self.beam_size = beam_size\n",
    "\n",
    "    def __call__(self, batch: List[List[List[Tuple[float, str]]]]) -> List[List[str]]:\n",
    "        \"\"\"Choose the best candidate for every token\n",
    "\n",
    "        Args:\n",
    "            batch: batch of probabilities and string values of candidates for every token in a sentence.\n",
    "            Ex.:\n",
    "            [\n",
    "                [\n",
    "                    [\n",
    "                        (-0.0, 'все'),(-4.0, 'вес'), (-4.0, 'вс'), (-4.0, 'всг'),(-4.0, 'вси'),\n",
    "                        (-4.0, 'вск'),(-4.0, 'всл'),(-4.0, 'овсе')],\n",
    "                    [\n",
    "                        (-0.0, 'смешалось'),(-4.0, 'смешало ь'),(-4.0, 'мешалось'),\n",
    "                        (-4.0, 'вмешалось'),(-4.0, 'с мешалось')],\n",
    "                    [\n",
    "                        (-0.0, 'кони'),(-4.0, 'кон'),(-4.0, 'кона'),(-4.0, 'конв'),\n",
    "                        (-4.0, 'коне'),(-4.0, 'конн'),(-4.0, 'коно'),(-4.0, 'клони')],\n",
    "                    [\n",
    "                        (-0.0, 'люди'),(-4.0, 'люд'),(-4.0, 'леди'),(-4.0, 'лю ди'),\n",
    "                        (-4.0, 'блюди')]\n",
    "                ]\n",
    "            ]\n",
    "\n",
    "        Returns:\n",
    "            batch of corrected tokenized sentences\n",
    "        \"\"\"\n",
    "        return [self._infer_instance(candidates) for candidates in batch]\n",
    "\n",
    "    def _infer_instance(self, candidates: List[List[Tuple[float, str]]]):\n",
    "        candidates = candidates + [[(0, '</s>')]]\n",
    "        state = kenlm.State()\n",
    "        self.lm.BeginSentenceWrite(state)\n",
    "        beam = [(0, state, [])]\n",
    "        for sublist in candidates:\n",
    "            new_beam = []\n",
    "            for beam_score, beam_state, beam_words in beam:\n",
    "                for score, candidate in sublist:\n",
    "                    prev_state = beam_state\n",
    "                    c_score = 0\n",
    "                    cs = candidate.split()\n",
    "                    for candidate in cs:\n",
    "                        state = kenlm.State()\n",
    "                        c_score += self.lm.BaseScore(prev_state, candidate, state)\n",
    "                        prev_state = state\n",
    "                    new_beam.append((beam_score + score + c_score, state, beam_words + cs))\n",
    "            new_beam.sort(reverse=True)\n",
    "            beam = new_beam[:self.beam_size]\n",
    "        score, state, words = beam[0]\n",
    "        return words[:-1]\n",
    "    \n",
    "    ##########################################################################\n",
    "    def _tokenize(self, sentence):\n",
    "        return sentence.split()\n",
    "    \n",
    "    def estimate_pure_likelihood(self, sentence):\n",
    "        \"\"\"Given a sentence it estimates its likelihood without spelling correction fixes\"\"\"\n",
    "        tokenized_sentence = self._tokenize(sentence)\n",
    "        # add /s\n",
    "        tokenized_sentence += ['</s>']\n",
    "        state = kenlm.State()\n",
    "        self.lm.BeginSentenceWrite(state)\n",
    "        beam = [(0, state, [])]\n",
    "        for word in tokenized_sentence:\n",
    "            #TODO\n",
    "            pass\n",
    "        \n",
    "    def estimate_likelihood_with_correction_scores(self, tokenized_sentence_with_correction_scores):\n",
    "        \"\"\"Given a sentence it estimates its likelihood with spelling correction fixes\"\"\"\n",
    "        #TODO\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"~/.deeppavlov\"\n",
    "DOWNLOADS_PATH = ROOT_PATH + \"/downloads\"\n",
    "kenlm_el = KenlmElector(load_path=DOWNLOADS_PATH+\"/language_models/ru_wiyalen_no_punkt.arpa.binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['все', 'смешалось', 'кони', 'люди']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kenlm_el([[\n",
    "                    [\n",
    "                        (-0.0, 'все'),(-4.0, 'вес'), (-4.0, 'вс'), (-4.0, 'всг'),(-4.0, 'вси'),\n",
    "                        (-4.0, 'вск'),(-4.0, 'всл'),(-4.0, 'овсе')],\n",
    "                    [\n",
    "                        (-0.0, 'смешалось'),(-4.0, 'смешало ь'),(-4.0, 'мешалось'),\n",
    "                        (-4.0, 'вмешалось'),(-4.0, 'с мешалось')],\n",
    "                    [\n",
    "                        (-0.0, 'кони'),(-4.0, 'кон'),(-4.0, 'кона'),(-4.0, 'конв'),\n",
    "                        (-4.0, 'коне'),(-4.0, 'конн'),(-4.0, 'коно'),(-4.0, 'клони')],\n",
    "                    [\n",
    "                        (-0.0, 'люди'),(-4.0, 'люд'),(-4.0, 'леди'),(-4.0, 'лю ди'),\n",
    "                        (-4.0, 'блюди')]\n",
    "                ]\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['все', 'смешалось', 'кони', 'люди']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kenlm_el._infer_instance([\n",
    "                    [\n",
    "                        (-0.0, 'все'),(-4.0, 'вес'), (-4.0, 'вс'), (-4.0, 'всг'),(-4.0, 'вси'),\n",
    "                        (-4.0, 'вск'),(-4.0, 'всл'),(-4.0, 'овсе')],\n",
    "                    [\n",
    "                        (-0.0, 'смешалось'),(-4.0, 'смешало ь'),(-4.0, 'мешалось'),\n",
    "                        (-4.0, 'вмешалось'),(-4.0, 'с мешалось')],\n",
    "                    [\n",
    "                        (-0.0, 'кони'),(-4.0, 'кон'),(-4.0, 'кона'),(-4.0, 'конв'),\n",
    "                        (-4.0, 'коне'),(-4.0, 'конн'),(-4.0, 'коно'),(-4.0, 'клони')],\n",
    "                    [\n",
    "                        (-0.0, 'люди'),(-4.0, 'люд'),(-4.0, 'леди'),(-4.0, 'лю ди'),\n",
    "                        (-4.0, 'блюди')]\n",
    "                ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3",
   "language": "python",
   "name": ".venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
