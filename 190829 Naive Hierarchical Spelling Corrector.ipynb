{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deeppavlov.models.spelling_correction.levenshtein.searcher_component import LevenshteinSearcherComponent\n",
    "import numpy as np\n",
    "DATA_PATH = \"/home/alx/Cloud/spell_corr/py_spelling_corrector/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp_components.kenlm_elector import KenlmElector\n",
    "from dp_components.levenshtein_searcher import LevenshteinSearcherComponent\n",
    "from dp_components.sc_candidates_generator import SpellingCorrectionCandidatesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy\n",
    "\n",
    "class LanguageModel():\n",
    "    def tokenize(self, sent_str):\n",
    "        pass\n",
    "\n",
    "    def estimate_likelihood(self, sent_str):\n",
    "        pass\n",
    "\n",
    "    def score_sentences(self, sentences):\n",
    "        return np.random.rand(len(sentences))\n",
    "\n",
    "class TokenHypothesis():\n",
    "    def __init__(self, text, err_score=0.0):\n",
    "        self.text = text\n",
    "#         self.lm_score = 0\n",
    "        # score for error:\n",
    "        self.err_score = err_score\n",
    "        # counter which helps to estimate how many words was merged\n",
    "        # this is used to multiply likelihood of unknown word\n",
    "        self.merges_count = 0\n",
    "        \n",
    "    def merge_with_suffix(self, suffix_str, err_score):\n",
    "        self.text += suffix_str\n",
    "        self.err_score += err_score\n",
    "        self.merges_count+=1\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"[HypoTok: %s]\" % self.text\n",
    "    \n",
    "class SentenceHypothesis():\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "#         self.score = np.nan\n",
    "        self.lm_score = 0\n",
    "        # score for error:\n",
    "#         self.err_score = err_score\n",
    "        self.final_score = 0.0\n",
    "        # token hypotheses of the sentence\n",
    "        self.token_hypotheses = []\n",
    "        \n",
    "    def total_score(self):\n",
    "        return self.lm_score+self.err_score()\n",
    "    \n",
    "    def err_score(self):\n",
    "        # calculates error score from token errors\n",
    "        total_error = 0\n",
    "        for each_tok_hyp in self.token_hypotheses:\n",
    "            total_error+=each_tok_hyp.err_score\n",
    "        return total_error\n",
    "    \n",
    "    def fork_for_each_suffix(self, suffixes, error_scores=None):\n",
    "        \"\"\"Given a list of suffixes strings it forks the current hypotheses into several\n",
    "        hypotheses for each suffix.\n",
    "\n",
    "        : param error_scores: score for suffix, usually negative value (logit score), suffix error score is incremented to\n",
    "        baseline hypothesis score\n",
    "        \"\"\"\n",
    "        hypotheses_list = []\n",
    "        #         import ipdb; ipdb.set_trace()\n",
    "        for idx, each_suffix in enumerate(suffixes):\n",
    "            new_sentence_hypothesis = deepcopy(self)\n",
    "            new_sentence_hypothesis.text += each_suffix\n",
    "\n",
    "            if each_suffix[0] == \" \":\n",
    "                # new token case\n",
    "                # if suffix starts with space character, then we have a token split\n",
    "                tok_hypothesis = TokenHypothesis(each_suffix[1:], error_scores[idx])\n",
    "                new_sentence_hypothesis.token_hypotheses.append(tok_hypothesis)\n",
    "\n",
    "            else:\n",
    "                # hypotheses of continuation of token\n",
    "                tokens_count = len(new_sentence_hypothesis.token_hypotheses)\n",
    "                if tokens_count == 0:\n",
    "                    # the first token in the sentence\n",
    "                    tok_hypothesis = TokenHypothesis(each_suffix, error_scores[idx])\n",
    "                    new_sentence_hypothesis.token_hypotheses.append(tok_hypothesis)\n",
    "\n",
    "                else:\n",
    "                    # get last token and merge it with suffix:\n",
    "                    last_token_hypothesis = new_sentence_hypothesis.token_hypotheses[\n",
    "                        tokens_count - 1]\n",
    "                    # TODO do we really need a deepcopy here? (I suppose token hypothesis is already deepcopied in sentencece hypothesis deepcopy?)\n",
    "                    last_token_hypothesis = deepcopy(last_token_hypothesis)\n",
    "#                     last_token_hypothesis.merge_with_suffix(each_suffix[1:], error_scores[idx])\n",
    "                    last_token_hypothesis.merge_with_suffix(each_suffix, error_scores[idx])\n",
    "                    # substitute the last token hypothesis with enlarged one\n",
    "                    new_sentence_hypothesis.token_hypotheses[\n",
    "                        tokens_count - 1] = last_token_hypothesis\n",
    "\n",
    "            hypotheses_list.append(new_sentence_hypothesis)\n",
    "\n",
    "        return hypotheses_list\n",
    "\n",
    "    def __repr__(self):        \n",
    "        if self.final_score!=0:\n",
    "            out_text = \" score: %f\" % self.final_score        \n",
    "        else:\n",
    "            out_text = \" score: %f\" % self.total_score()        \n",
    "        text = \"hypothesis: %s\" % self.text\n",
    "        return text + out_text\n",
    "    \n",
    "class HypothesesHub():\n",
    "    def __init__(self):\n",
    "        # init with null hypothesis:\n",
    "        self.hypotheses = [SentenceHypothesis(\"\")]\n",
    "\n",
    "    def get_scores(self):\n",
    "        \"\"\"Returns summarized scores Error + LM score\"\"\"\n",
    "        scores = [each_hypo.total_score() for each_hypo in self.hypotheses]\n",
    "        return scores\n",
    "\n",
    "    def append_partial_hypotheses(self, partial_candidates, error_scores=None):\n",
    "        \"\"\"\n",
    "        For each hypothesis in the hub it appends all candidates\n",
    "        :param partial_candidates:\n",
    "        :return: updated self\n",
    "        \"\"\"\n",
    "        new_hypotheses = []\n",
    "        if self.hypotheses:\n",
    "            for each_hypothesis in self.hypotheses:\n",
    "                hypos = each_hypothesis.fork_for_each_suffix(partial_candidates, error_scores=error_scores)\n",
    "                new_hypotheses += hypos\n",
    "        else:\n",
    "            print(\"No hypotheses!!!!\")\n",
    "        self.hypotheses = new_hypotheses\n",
    "        return self\n",
    "\n",
    "    \n",
    "class SpellingCorrector():\n",
    "    # language_model;\n",
    "    # error model;\n",
    "    def __init__(self, sccg=None, language_model=None):\n",
    "        \"\"\"\n",
    "        sccg - spelling corrector hypotheses generator instance\n",
    "        lang_model - language model instance, by default KenLM\n",
    "        \"\"\"\n",
    "        \n",
    "        # setup hypotheses generator:\n",
    "        if not sccg:\n",
    "            self.sccg = SpellingCorrectionCandidatesGenerator()\n",
    "        else:\n",
    "            self.sccg = sccg\n",
    "        \n",
    "        # setup language model:\n",
    "        if not language_model:\n",
    "            # KenLM Elector as LM:\n",
    "            ROOT_PATH = \"~/.deeppavlov\"\n",
    "            DOWNLOADS_PATH = ROOT_PATH + \"/downloads\"        \n",
    "            self.lm = KenlmElector(load_path=DOWNLOADS_PATH+\"/language_models/ru_wiyalen_no_punkt.arpa.binary\")\n",
    "\n",
    "        else:\n",
    "            self.lm = language_model\n",
    "    \n",
    "    def score_hypothesis(self, sentence_hypothesis):\n",
    "        \"\"\"Scores hypothesis by KenLM with accounting \"\"\"\n",
    "        state = kenlm.State()\n",
    "        prev_state = state\n",
    "        self.lm.lm.NullContextWrite(state)\n",
    "        accum = 0.0\n",
    "        for each_tok_hyp in sentence_hypothesis.token_hypotheses:\n",
    "            next_state = kenlm.State()\n",
    "            uniscore= self.lm.lm.BaseScore(prev_state, each_tok_hyp.text, next_state)\n",
    "            if each_tok_hyp.merges_count>0:\n",
    "                # check each_tok_hyp is OOV! otherwise heuristics is incorrect\n",
    "                uniscore *= each_tok_hyp.merges_count+1\n",
    "            if each_tok_hyp.err_score:\n",
    "                assert each_tok_hyp.err_score<=0\n",
    "                uniscore += each_tok_hyp.err_score\n",
    "#             print(each_tok_hyp, uniscore)\n",
    "            accum += uniscore\n",
    "            prev_state = next_state\n",
    "        return accum\n",
    "            \n",
    "            \n",
    "    def score_hypotheses_hub(self, hypotheses_hub):\n",
    "        \"\"\"Score hypotheses by LM\n",
    "        Command to run scoring of all hypotheses by language model scoring function\n",
    "        :return: list of scored hypotheses\n",
    "        \n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        for each_sentence_hypothesis in hypotheses_hub.hypotheses:\n",
    "            each_sentence_hypothesis.final_score = self.score_hypothesis(each_sentence_hypothesis)\n",
    "            scores.append(each_sentence_hypothesis.final_score)\n",
    "            \n",
    "        return scores\n",
    "\n",
    "    def score_hypotheses_hub_optimized(self, hypotheses_hub):\n",
    "        \"\"\"Score hypotheses by LM\n",
    "        \n",
    "        Command to run scoring of all hypotheses by language model scoring function\n",
    "        \n",
    "        Optimized version.\n",
    "        \n",
    "        We need to preprocess all hypotheses by creating prefix tree and using beam search to avoid \n",
    "        combinatorial blast\n",
    "        \n",
    "        \n",
    "        :return: list of scored hypotheses\n",
    "        \n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        for each_sentence_hypothesis in hypotheses_hub.hypotheses:\n",
    "            each_sentence_hypothesis.final_score = self.score_hypothesis(each_sentence_hypothesis)\n",
    "            scores.append(each_sentence_hypothesis.final_score)\n",
    "            \n",
    "        return scores\n",
    "    \n",
    "    def prune_low_prob_hypotheses(self, hypo_hub, max_number_of_hypotheses=200):\n",
    "        \"\"\"\n",
    "        Prunes hypotheses that has low probability.\n",
    "                \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        # number check\n",
    "        hypo_hub.hypotheses = sorted(hypo_hub.hypotheses, key=lambda x: x.final_score, reverse=True)        \n",
    "        if len(hypo_hub.hypotheses)>max_number_of_hypotheses:\n",
    "            # prune those which are the worst\n",
    "            hypo_hub.hypotheses = hypo_hub.hypotheses[:max_number_of_hypotheses]     \n",
    "        \n",
    "        return hypo_hub.hypotheses\n",
    "    \n",
    "    def analyze_sentence(self, sentence):\n",
    "        \"\"\"\n",
    "        Method for analyzing sentence: generating hypotheses and scoring them\n",
    "        \n",
    "        :param sentence: str, sentence with errors\n",
    "        :return: correction hypotheses of the sentence\n",
    "        \"\"\"\n",
    "        self.hypo_hub = HypothesesHub()\n",
    "        # preprocessing:\n",
    "        # TODO make lowercasing revertible:\n",
    "        sentence = self.lowercase(sentence)        \n",
    "        tokenized_input = self._tokenize(sentence)\n",
    "        for idx, each_tok in enumerate(tokenized_input):\n",
    "            # TODO optionally you could pass left and right context\n",
    "            err_scores, tok_candidates = self.sccg.gen_candidates(each_tok)\n",
    "            if idx>0:\n",
    "                # TODO optionally you could pass left and right context\n",
    "                err_scores, tok_candidates = self.sccg.variate_with_prefixes(tok_candidates, err_scores)\n",
    "            \n",
    "            self.hypo_hub = self.hypo_hub.append_partial_hypotheses(tok_candidates, err_scores)\n",
    "            \n",
    "            # group hypotheses by tokenized lengths and then use standrd KenLM scoring function?\n",
    "            l_scores = self.score_hypotheses_hub(self.hypo_hub)\n",
    "            self.prune_low_prob_hypotheses(self.hypo_hub)\n",
    "            \n",
    "        return self.hypo_hub.hypotheses\n",
    "    \n",
    "    def __call__(self, input_sentences_batch):\n",
    "        \"\"\"\n",
    "        Given a batch of sentences it returns a batch of corrected sentences\n",
    "        \n",
    "        \"\"\"\n",
    "        outputs = []\n",
    "        for each_sent in input_sentences_batch:\n",
    "            hypotheses = self.analyze_sentence(each_sent)\n",
    "            the_best_hypothesis = hypotheses[0]\n",
    "            outputs.append(the_best_hypothesis.text)\n",
    "        return outputs\n",
    "    \n",
    "    def lowercase(self, sent_str):\n",
    "        return sent_str.lower()\n",
    "    \n",
    "    def _tokenize(self, sent_str):\n",
    "        return sent_str.split()\n",
    "\n",
    "    def predict_correct(self, sentence_str):\n",
    "        \"\"\"\n",
    "        predicts correction of the sentence\n",
    "        :param sentence_str:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "    \n",
    "# UNFINISHED\n",
    "# class SpellingCorrectorGraphy(SpellingCorrector):\n",
    "#     \"\"\"\n",
    "#     The spelling corrector which uses graph representation of hypothesis space\n",
    "#     \"\"\"\n",
    "#     def analyze_sentence(self, sentence):\n",
    "#         \"\"\"\n",
    "#         Method for analyzing sentence: generating hypotheses and scoring them\n",
    "        \n",
    "#         :param sentence: str, sentence with errors\n",
    "#         :return: correction hypotheses of the sentence\n",
    "#         \"\"\"\n",
    "#         self.hypo_hub = HypothesesHub()\n",
    "#         # preprocessing:\n",
    "#         # TODO make lowercasing revertible:\n",
    "#         sentence = self.lowercase(sentence)        \n",
    "#         tokenized_input = self._tokenize(sentence)\n",
    "#         for idx, each_tok in enumerate(tokenized_input):\n",
    "#             # TODO optionally you could pass left and right context\n",
    "#             err_scores, tok_candidates = self.sccg.gen_candidates(each_tok)\n",
    "#             if idx>0:\n",
    "#                 # TODO optionally you could pass left and right context\n",
    "#                 err_scores, tok_candidates = self.sccg.variate_with_prefixes(tok_candidates, err_scores)\n",
    "            \n",
    "#             self.hypo_hub = self.hypo_hub.append_partial_hypotheses(tok_candidates, err_scores)\n",
    "            \n",
    "#             # group hypotheses by tokenized lengths and then use standrd KenLM scoring function?\n",
    "#             l_scores = self.score_hypotheses_hub(self.hypo_hub)\n",
    "#             self.prune_low_prob_hypotheses(self.hypo_hub)\n",
    "            \n",
    "#         return self.hypo_hub.hypotheses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-6.0, 0.0, -4.0], ['то', ' то', '-то'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sccg.variate_with_prefixes([\"то\"], [0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init it once because it loads for 2.5 minutes:\n",
    "sccg = SpellingCorrectionCandidatesGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SpellingCorrector(sccg=sccg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[hypothesis: когда нибудь score: -7.640179,\n",
       " hypothesis: когда-нибудь score: -12.643865,\n",
       " hypothesis: тогда нибудь score: -14.637478,\n",
       " hypothesis: кода нибудь score: -15.689139,\n",
       " hypothesis: когда ни будь score: -16.147324,\n",
       " hypothesis: корда нибудь score: -17.100760,\n",
       " hypothesis: когданибудь score: -18.130759,\n",
       " hypothesis: ко да нибудь score: -18.561239,\n",
       " hypothesis: тогда ни будь score: -20.326597,\n",
       " hypothesis: кода ни будь score: -21.378259,\n",
       " hypothesis: кода-нибудь score: -22.004326,\n",
       " hypothesis: тогда-нибудь score: -22.250359,\n",
       " hypothesis: корда-нибудь score: -22.250359,\n",
       " hypothesis: ко да-нибудь score: -22.250359,\n",
       " hypothesis: когдани будь score: -22.750359,\n",
       " hypothesis: тогданибудь score: -22.750359,\n",
       " hypothesis: коданибудь score: -22.750359,\n",
       " hypothesis: корданибудь score: -22.750359,\n",
       " hypothesis: ко данибудь score: -22.750359,\n",
       " hypothesis: корда ни будь score: -22.789880,\n",
       " hypothesis: ко да ни будь score: -24.250359,\n",
       " hypothesis: тогдани будь score: -26.750359,\n",
       " hypothesis: кодани будь score: -26.750359,\n",
       " hypothesis: кордани будь score: -26.750359,\n",
       " hypothesis: ко дани будь score: -26.750359]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses = sc.analyze_sentence(\"когда нибудь\")\n",
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-4.0, 0], ['ни будь', 'нибудь'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sccg.gen_candidates(\"нибудь\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[(-4.0, 'ни будь'), (0, 'нибудь')]]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sccg.lsc([[\"нибудь\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ни будь', 'нибудь'] [-4.0, -8.0]\n"
     ]
    }
   ],
   "source": [
    "scored_candidates=sccg.lsc([[\"нибудь\"]])[0][0]\n",
    "scores, w_forms = zip(*scored_candidates)\n",
    "w_forms = list(w_forms)\n",
    "scores = list(scores)\n",
    "print(w_forms, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0, -4.0, -4.0, -4.0, -4.0] ['когда', 'кода', 'корда', 'ко да', 'тогда']\n",
      "[-4.0, 0] ['ни будь', 'нибудь']\n",
      "[hypothesis: когда нибудь score: -7.640179, hypothesis: когда-нибудь score: -12.643865, hypothesis: тогда нибудь score: -14.637478, hypothesis: кода нибудь score: -15.689139, hypothesis: когда ни будь score: -16.147324, hypothesis: корда нибудь score: -17.100760, hypothesis: когданибудь score: -18.130759, hypothesis: ко да нибудь score: -18.561239, hypothesis: тогда ни будь score: -20.326597, hypothesis: кода ни будь score: -21.378259, hypothesis: кода-нибудь score: -22.004326, hypothesis: тогда-нибудь score: -22.250359, hypothesis: корда-нибудь score: -22.250359, hypothesis: ко да-нибудь score: -22.250359, hypothesis: когдани будь score: -22.750359, hypothesis: тогданибудь score: -22.750359, hypothesis: коданибудь score: -22.750359, hypothesis: корданибудь score: -22.750359, hypothesis: ко данибудь score: -22.750359, hypothesis: корда ни будь score: -22.789880, hypothesis: ко да ни будь score: -24.250359, hypothesis: тогдани будь score: -26.750359, hypothesis: кодани будь score: -26.750359, hypothesis: кордани будь score: -26.750359, hypothesis: ко дани будь score: -26.750359]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"когда нибудь\"\n",
    "hypo_hub = HypothesesHub()\n",
    "\n",
    "tokenized_input = sc._tokenize(sentence)\n",
    "for idx, each_tok in enumerate(tokenized_input):\n",
    "    # TODO optionally you could pass left and right context\n",
    "    err_scores, tok_candidates = sccg.gen_candidates(each_tok)\n",
    "    print(err_scores, tok_candidates)\n",
    "    if idx>0:\n",
    "        # TODO optionally you could pass left and right context\n",
    "        err_scores, tok_candidates = sccg.variate_with_prefixes(tok_candidates, err_scores)\n",
    "\n",
    "    hypo_hub = hypo_hub.append_partial_hypotheses(tok_candidates, err_scores)\n",
    "\n",
    "    # group hypotheses by tokenized lengths and then use standrd KenLM scoring function?\n",
    "    l_scores = sc.score_hypotheses_hub(hypo_hub)\n",
    "    sc.prune_low_prob_hypotheses(hypo_hub)\n",
    "\n",
    "print(hypo_hub.hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses[2].err_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses[3].token_hypotheses[0].err_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'когда-нибудь'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses[3].token_hypotheses[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[hypothesis: привет пампушка score: -17.856689,\n",
       " hypothesis: привет подпушка score: -18.043473,\n",
       " hypothesis: привет помпу ка score: -18.166489,\n",
       " hypothesis: привет пом ушка score: -18.166489,\n",
       " hypothesis: привет помп ушка score: -18.166489,\n",
       " hypothesis: привет попушка score: -18.166489,\n",
       " hypothesis: привет по пушка score: -18.166489,\n",
       " hypothesis: привет пом пушка score: -18.166489,\n",
       " hypothesis: привел пампушка score: -20.849180,\n",
       " hypothesis: примет пампушка score: -20.957743,\n",
       " hypothesis: привел подпушка score: -21.035964,\n",
       " hypothesis: примет подпушка score: -21.144526,\n",
       " hypothesis: привел помпу ка score: -21.158980,\n",
       " hypothesis: привел пом ушка score: -21.158980,\n",
       " hypothesis: привел помп ушка score: -21.158980,\n",
       " hypothesis: привел попушка score: -21.158980,\n",
       " hypothesis: привел по пушка score: -21.158980,\n",
       " hypothesis: привел пом пушка score: -21.158980,\n",
       " hypothesis: примет помпу ка score: -21.267542,\n",
       " hypothesis: примет пом ушка score: -21.267542,\n",
       " hypothesis: примет помп ушка score: -21.267542,\n",
       " hypothesis: примет попушка score: -21.267542,\n",
       " hypothesis: примет по пушка score: -21.267542,\n",
       " hypothesis: примет пом пушка score: -21.267542,\n",
       " hypothesis: привез пампушка score: -21.289653,\n",
       " hypothesis: придет пампушка score: -21.331102,\n",
       " hypothesis: привез подпушка score: -21.476437,\n",
       " hypothesis: придет подпушка score: -21.517886,\n",
       " hypothesis: привез помпу ка score: -21.599453,\n",
       " hypothesis: привез пом ушка score: -21.599453,\n",
       " hypothesis: привез помп ушка score: -21.599453,\n",
       " hypothesis: привез попушка score: -21.599453,\n",
       " hypothesis: привез по пушка score: -21.599453,\n",
       " hypothesis: привез пом пушка score: -21.599453,\n",
       " hypothesis: придет помпу ка score: -21.640902,\n",
       " hypothesis: придет пом ушка score: -21.640902,\n",
       " hypothesis: придет помп ушка score: -21.640902,\n",
       " hypothesis: придет попушка score: -21.640902,\n",
       " hypothesis: придет по пушка score: -21.640902,\n",
       " hypothesis: придет пом пушка score: -21.640902,\n",
       " hypothesis: привет помпушка score: -22.166489,\n",
       " hypothesis: прилет пампушка score: -22.396225,\n",
       " hypothesis: прилет подпушка score: -22.583009,\n",
       " hypothesis: приветы пампушка score: -22.647849,\n",
       " hypothesis: прилет помпу ка score: -22.706026,\n",
       " hypothesis: прилет пом ушка score: -22.706026,\n",
       " hypothesis: прилет помп ушка score: -22.706026,\n",
       " hypothesis: прилет попушка score: -22.706026,\n",
       " hypothesis: прилет по пушка score: -22.706026,\n",
       " hypothesis: прилет пом пушка score: -22.706026,\n",
       " hypothesis: привит пампушка score: -22.762745,\n",
       " hypothesis: приветы подпушка score: -22.834631,\n",
       " hypothesis: привес пампушка score: -22.837011,\n",
       " hypothesis: привит подпушка score: -22.949529,\n",
       " hypothesis: приветы помпу ка score: -22.957648,\n",
       " hypothesis: приветы пом ушка score: -22.957648,\n",
       " hypothesis: приветы помп ушка score: -22.957648,\n",
       " hypothesis: приветы попушка score: -22.957648,\n",
       " hypothesis: приветы по пушка score: -22.957648,\n",
       " hypothesis: приветы пом пушка score: -22.957648,\n",
       " hypothesis: привета пампушка score: -22.991599,\n",
       " hypothesis: привес подпушка score: -23.023794,\n",
       " hypothesis: привит помпу ка score: -23.072546,\n",
       " hypothesis: привит пом ушка score: -23.072546,\n",
       " hypothesis: привит помп ушка score: -23.072546,\n",
       " hypothesis: привит попушка score: -23.072546,\n",
       " hypothesis: привит по пушка score: -23.072546,\n",
       " hypothesis: привит пом пушка score: -23.072546,\n",
       " hypothesis: привес помпу ка score: -23.146810,\n",
       " hypothesis: привес пом ушка score: -23.146810,\n",
       " hypothesis: привес помп ушка score: -23.146810,\n",
       " hypothesis: привес попушка score: -23.146810,\n",
       " hypothesis: привес по пушка score: -23.146810,\n",
       " hypothesis: привес пом пушка score: -23.146810,\n",
       " hypothesis: привьет пампушка score: -23.147938,\n",
       " hypothesis: привета подпушка score: -23.178382,\n",
       " hypothesis: причет пампушка score: -23.178753,\n",
       " hypothesis: привета помпу ка score: -23.301398,\n",
       " hypothesis: привета пом ушка score: -23.301398,\n",
       " hypothesis: привета помп ушка score: -23.301398,\n",
       " hypothesis: привета попушка score: -23.301398,\n",
       " hypothesis: привета по пушка score: -23.301398,\n",
       " hypothesis: привета пом пушка score: -23.301398,\n",
       " hypothesis: привьет подпушка score: -23.334722,\n",
       " hypothesis: причет подпушка score: -23.365536,\n",
       " hypothesis: приват пампушка score: -23.393684,\n",
       " hypothesis: привьет помпу ка score: -23.457738,\n",
       " hypothesis: привьет пом ушка score: -23.457738,\n",
       " hypothesis: привьет помп ушка score: -23.457738,\n",
       " hypothesis: привьет попушка score: -23.457738,\n",
       " hypothesis: привьет по пушка score: -23.457738,\n",
       " hypothesis: привьет пом пушка score: -23.457738,\n",
       " hypothesis: причет помпу ка score: -23.488553,\n",
       " hypothesis: причет пом ушка score: -23.488553,\n",
       " hypothesis: причет помп ушка score: -23.488553,\n",
       " hypothesis: причет попушка score: -23.488553,\n",
       " hypothesis: причет по пушка score: -23.488553,\n",
       " hypothesis: причет пом пушка score: -23.488553,\n",
       " hypothesis: приват подпушка score: -23.580467,\n",
       " hypothesis: приват помпу ка score: -23.703484,\n",
       " hypothesis: приват пом ушка score: -23.703484,\n",
       " hypothesis: приват помп ушка score: -23.703484,\n",
       " hypothesis: приват попушка score: -23.703484,\n",
       " hypothesis: приват по пушка score: -23.703484,\n",
       " hypothesis: приват пом пушка score: -23.703484,\n",
       " hypothesis: привете пампушка score: -23.912977,\n",
       " hypothesis: привей пампушка score: -23.940559,\n",
       " hypothesis: привето пампушка score: -23.940559,\n",
       " hypothesis: привету пампушка score: -23.940559,\n",
       " hypothesis: приветь пампушка score: -23.940559,\n",
       " hypothesis: при ет пампушка score: -23.940559,\n",
       " hypothesis: приврет пампушка score: -23.940559,\n",
       " hypothesis: пр вет пампушка score: -23.940559,\n",
       " hypothesis: при вет пампушка score: -23.940559,\n",
       " hypothesis: п ивет пампушка score: -23.940559,\n",
       " hypothesis: пр ивет пампушка score: -23.940559,\n",
       " hypothesis: привете подпушка score: -24.099760,\n",
       " hypothesis: привей подпушка score: -24.127342,\n",
       " hypothesis: привето подпушка score: -24.127342,\n",
       " hypothesis: привету подпушка score: -24.127342,\n",
       " hypothesis: приветь подпушка score: -24.127342,\n",
       " hypothesis: при ет подпушка score: -24.127342,\n",
       " hypothesis: приврет подпушка score: -24.127342,\n",
       " hypothesis: пр вет подпушка score: -24.127342,\n",
       " hypothesis: при вет подпушка score: -24.127342,\n",
       " hypothesis: п ивет подпушка score: -24.127342,\n",
       " hypothesis: пр ивет подпушка score: -24.127342,\n",
       " hypothesis: привете помпу ка score: -24.222776,\n",
       " hypothesis: привете пом ушка score: -24.222776,\n",
       " hypothesis: привете помп ушка score: -24.222776,\n",
       " hypothesis: привете попушка score: -24.222776,\n",
       " hypothesis: привете по пушка score: -24.222776,\n",
       " hypothesis: привете пом пушка score: -24.222776,\n",
       " hypothesis: привей помпу ка score: -24.250359,\n",
       " hypothesis: привей пом ушка score: -24.250359,\n",
       " hypothesis: привей помп ушка score: -24.250359,\n",
       " hypothesis: привей попушка score: -24.250359,\n",
       " hypothesis: привей по пушка score: -24.250359,\n",
       " hypothesis: привей пом пушка score: -24.250359,\n",
       " hypothesis: привето помпу ка score: -24.250359,\n",
       " hypothesis: привето пом ушка score: -24.250359,\n",
       " hypothesis: привето помп ушка score: -24.250359,\n",
       " hypothesis: привето попушка score: -24.250359,\n",
       " hypothesis: привето по пушка score: -24.250359,\n",
       " hypothesis: привето пом пушка score: -24.250359,\n",
       " hypothesis: привету помпу ка score: -24.250359,\n",
       " hypothesis: привету пом ушка score: -24.250359,\n",
       " hypothesis: привету помп ушка score: -24.250359,\n",
       " hypothesis: привету попушка score: -24.250359,\n",
       " hypothesis: привету по пушка score: -24.250359,\n",
       " hypothesis: привету пом пушка score: -24.250359,\n",
       " hypothesis: приветь помпу ка score: -24.250359,\n",
       " hypothesis: приветь пом ушка score: -24.250359,\n",
       " hypothesis: приветь помп ушка score: -24.250359,\n",
       " hypothesis: приветь попушка score: -24.250359,\n",
       " hypothesis: приветь по пушка score: -24.250359,\n",
       " hypothesis: приветь пом пушка score: -24.250359,\n",
       " hypothesis: при ет помпу ка score: -24.250359,\n",
       " hypothesis: при ет пом ушка score: -24.250359,\n",
       " hypothesis: при ет помп ушка score: -24.250359,\n",
       " hypothesis: при ет попушка score: -24.250359,\n",
       " hypothesis: при ет по пушка score: -24.250359,\n",
       " hypothesis: при ет пом пушка score: -24.250359,\n",
       " hypothesis: приврет помпу ка score: -24.250359,\n",
       " hypothesis: приврет пом ушка score: -24.250359,\n",
       " hypothesis: приврет помп ушка score: -24.250359,\n",
       " hypothesis: приврет попушка score: -24.250359,\n",
       " hypothesis: приврет по пушка score: -24.250359,\n",
       " hypothesis: приврет пом пушка score: -24.250359,\n",
       " hypothesis: пр вет помпу ка score: -24.250359,\n",
       " hypothesis: пр вет пом ушка score: -24.250359,\n",
       " hypothesis: пр вет помп ушка score: -24.250359,\n",
       " hypothesis: пр вет попушка score: -24.250359,\n",
       " hypothesis: пр вет по пушка score: -24.250359,\n",
       " hypothesis: пр вет пом пушка score: -24.250359,\n",
       " hypothesis: при вет помпу ка score: -24.250359,\n",
       " hypothesis: при вет пом ушка score: -24.250359,\n",
       " hypothesis: при вет помп ушка score: -24.250359,\n",
       " hypothesis: при вет попушка score: -24.250359,\n",
       " hypothesis: при вет по пушка score: -24.250359,\n",
       " hypothesis: при вет пом пушка score: -24.250359,\n",
       " hypothesis: п ивет помпу ка score: -24.250359,\n",
       " hypothesis: п ивет пом ушка score: -24.250359,\n",
       " hypothesis: п ивет помп ушка score: -24.250359,\n",
       " hypothesis: п ивет попушка score: -24.250359,\n",
       " hypothesis: п ивет по пушка score: -24.250359,\n",
       " hypothesis: п ивет пом пушка score: -24.250359,\n",
       " hypothesis: пр ивет помпу ка score: -24.250359,\n",
       " hypothesis: пр ивет пом ушка score: -24.250359,\n",
       " hypothesis: пр ивет помп ушка score: -24.250359,\n",
       " hypothesis: пр ивет попушка score: -24.250359,\n",
       " hypothesis: пр ивет по пушка score: -24.250359,\n",
       " hypothesis: пр ивет пом пушка score: -24.250359,\n",
       " hypothesis: привел помпушка score: -25.158980,\n",
       " hypothesis: примет помпушка score: -25.267542,\n",
       " hypothesis: привез помпушка score: -25.599453,\n",
       " hypothesis: придет помпушка score: -25.640902,\n",
       " hypothesis: приветпомпу ка score: -26.250359,\n",
       " hypothesis: приветпом ушка score: -26.250359,\n",
       " hypothesis: приветпомп ушка score: -26.250359]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses = sc.analyze_sentence(\"привет помпушка\")\n",
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[hypothesis: мыприехали вдеревню score: -16.250359,\n",
       " hypothesis: мыприехали деревню score: -16.987349,\n",
       " hypothesis: мыприехаливдеревню score: -18.750359,\n",
       " hypothesis: мыприехали в деревню score: -20.250359,\n",
       " hypothesis: м приехали вдеревню score: -20.250359,\n",
       " hypothesis: мы приехали вдеревню score: -20.250359,\n",
       " hypothesis: м приехали деревню score: -20.987349,\n",
       " hypothesis: мы приехали деревню score: -20.987349,\n",
       " hypothesis: мыприехалидеревню score: -22.750359,\n",
       " hypothesis: мыприехалив деревню score: -22.750359,\n",
       " hypothesis: м приехаливдеревню score: -22.750359,\n",
       " hypothesis: мы приехаливдеревню score: -22.750359,\n",
       " hypothesis: м приехали в деревню score: -24.250359,\n",
       " hypothesis: мы приехали в деревню score: -24.250359,\n",
       " hypothesis: м приехалидеревню score: -26.750359,\n",
       " hypothesis: м приехалив деревню score: -26.750359,\n",
       " hypothesis: мы приехалидеревню score: -26.750359,\n",
       " hypothesis: мы приехалив деревню score: -26.750359]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses = sc.analyze_sentence(\"мыприехали вдеревню\")\n",
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses[13].err_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALOG_DATA_PATH = 'data/dialog/'\n",
    "# Train data\n",
    "TRAIN_ERRONEOUS_DATA = DIALOG_DATA_PATH + \"source_sents.txt\"\n",
    "TRAIN_GOLDEN_DATA = DIALOG_DATA_PATH + \"corrected_sents.txt\"\n",
    "\n",
    "# Test data\n",
    "TEST_ERRONEOUS_DATA = DIALOG_DATA_PATH + \"test_sample_testset.txt\"\n",
    "TEST_GOLDEN_DATA = DIALOG_DATA_PATH + \"corr_sample_testset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEST_ERRONEOUS_DATA, 'r') as sents_file:\n",
    "    erroneous_lines = sents_file.readlines()\n",
    "    erroneous_lines = [line.strip() for line in erroneous_lines]\n",
    "    \n",
    "with open(TEST_GOLDEN_DATA, 'r') as sents_file:\n",
    "    golden_lines = sents_file.readlines()\n",
    "    golden_lines = [line.strip() for line in golden_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluate_spelling_corrector\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:34.719621\n"
     ]
    }
   ],
   "source": [
    "start_index=4\n",
    "fin_index = 13\n",
    "start_dt = dt.datetime.now()\n",
    "hypotheses = sc(erroneous_lines[start_index:fin_index])\n",
    "fin_dt = dt.datetime.now()\n",
    "print(fin_dt-start_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['судьба человека может складываться очень разнообразно в жизни много прекрасных светлых радостных моментов',\n",
       " 'а я думаю вот если бы хозяин этой лодки тебе ее подарил и ты бы собрал знакомых и устроил на этой лодке большие катание с размахом',\n",
       " 'например парадный портрет николая ii при орденах и регалиях освященный как икона и снабженный 5-рублевой монетой и роскошным текстом снизу',\n",
       " 'двубортное кашемировое пальто песочного цвета классическог фасона',\n",
       " 'поговорила с директором и он мне обещал позвонить вечером и сказать берет он меня на работу',\n",
       " 'схездил потом в ркб оказалось что на нем 3 царапины купил мази и капли',\n",
       " 'но даже когда мы приблизились к нижнему уровню замка я поверить не могла что он такой огромный как показывалось на карте',\n",
       " 'давно стоит понять что в этой жизни никто не делает так как лутче тебе',\n",
       " 'а вообще конечно не представляю как все пятьдесят лет все забавляются над дядькой']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=75.00 Recall=42.86 FMeasure=54.55\n",
      "3 4 7\n",
      "0.75\n",
      "0.42857142857142855\n",
      "0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_spelling_corrector(erroneous_lines[start_index:fin_index], \n",
    "                                      golden_lines[start_index:fin_index], \n",
    "                                      hypotheses)\n",
    "print(results['precision'])\n",
    "print(results['recall'])\n",
    "print(results['f_measure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = dt.datetime.now()\n",
    "hypotheses = sc(erroneous_lines)\n",
    "fin_dt = dt.datetime.now()\n",
    "print(fin_dt-start_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=54.67 Recall=57.13 FMeasure=55.87\n",
      "1130 2067 1978\n",
      "0.5466860183841316\n",
      "0.5712841253791708\n",
      "0.5587144622991348\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_spelling_corrector(erroneous_lines, golden_lines, hypotheses)\n",
    "print(results['precision'])\n",
    "print(results['recall'])\n",
    "print(results['f_measure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erroneous_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Based Hypotheses Trimmer\n",
    "\n",
    "Assumptions:\n",
    "1. We have a graph of token hypotheses \n",
    "2. we have a autoregressive language model LM\n",
    "3. Graph has a root node (the place where all sentence hypotheses starts)\n",
    "4. Algorithm goes through a graph with breadth search\n",
    "5. and iteratively trims bad hypotheses from analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HypothesesGraph():\n",
    "    \"\"\"\n",
    "    sentence hypotheses\n",
    "    tokens hypotheses\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.root_node = None\n",
    "        self.fin_node = None\n",
    "\n",
    "    def calculate_lm_scores(self, lm_obj):\n",
    "        \"\"\"\n",
    "        Runs the process of calculation of hypotheses scores\n",
    "        \n",
    "        1. Starts from fin_node and requests prefix_hypotheses.\n",
    "        2. \n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "        \n",
    "class GraphNode():\n",
    "    \"\"\" \n",
    "    A token hypothesis of segment of Input Sentence\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, token_hypothesis):\n",
    "        # partial hypotheses that are produced after attaching this node to all prefixes hypotheses\n",
    "        self.output_hypotheses = []\n",
    "        \n",
    "        # boolean flag that marks that all prefix hypotheses are calculated\n",
    "        self.calculated_outputs = False\n",
    "        \n",
    "        self.token_hypothesis = token_hypothesis\n",
    "    \n",
    "    def get_prefix_hypotheses(self, top_k=-1):\n",
    "        \"\"\"\n",
    "        For a node collects hypotheses from previous stage (all parent nodes) \n",
    "        and filters out the ones with low likelihood\n",
    "        \"\"\"\n",
    "        prefix_hypotheses = []\n",
    "        for each_prefix_node in self.from:        \n",
    "            if len(each_prefix_node.output_hypotheses)>0:\n",
    "                prefix_hypotheses += each_prefix_node.output_hypotheses\n",
    "            else:\n",
    "                raise Exception(\"prefix Node %s is unfilled!\" % each_prefix_node)\n",
    "        \n",
    "        hypos = sorted(prefix_hypotheses, key=lambda x: x.lm_score(), reverse=True)\n",
    "        \n",
    "        if top_k>0:\n",
    "            # make pruning:\n",
    "            hypos = hypos[:top_k]\n",
    "            \n",
    "        return hypos\n",
    "    \n",
    "    def push_to_output_hypotheses(self, hypothesis):\n",
    "        \"\"\"\n",
    "        adds a hypothesis into list of output hypotheses\n",
    "        \"\"\"\n",
    "        self.output_hypotheses.append(hypothesis)\n",
    "\n",
    "\n",
    "def calculate_output_hypotheses_for_node(node, lm):\n",
    "    \"\"\"\n",
    "    Calculates output_hypotheses for a node using prefix_hypotheses and information about node's TokenHypothesis\n",
    "    \"\"\"\n",
    "    partial_sentence_hypotheses = node.get_prefix_hypotheses(top_k=-1)\n",
    "    \n",
    "    # to assure that we dont append twice\n",
    "    assert len(node.output_hypotheses)==0\n",
    "    \n",
    "    for each_input_hypothesis in partial_sentence_hypotheses:\n",
    "\n",
    "        output_hypothesis, score = lm.score(each_input_hypothesis, each_child.token_hypothesis)\n",
    "\n",
    "        node.push_to_output_hypotheses(output_hypothesis)\n",
    "    return node\n",
    "\n",
    "\n",
    "def analyze_with_lm(graph, lm, start_node=None):\n",
    "    \"\"\"\n",
    "    Method to calculate likelihoods one stage deeper\n",
    "    \"\"\"\n",
    "    if not start_node:\n",
    "        current_node = graph.root_node        \n",
    "    else: \n",
    "        current_node = start_node\n",
    "        \n",
    "    for each_child in current_node.to:\n",
    "        # each_child has a set of prefix hypotheses\n",
    "        # we need to calc them all\n",
    "        \n",
    "        each_child = calculate_output_hypotheses_for_node(each_child, lm)\n",
    "        # add chld to agenda?\n",
    "        # how to avoid adding twice?\n",
    "        \n",
    "        # node is finished. we can go deeper\n",
    "    \n",
    "    # here all children are processed and we can go deeper    \n",
    "    return current_node.to \n",
    "        \n",
    "\n",
    "def analyze_graph_with_lm(graph, lm):\n",
    "    agenda = [graph.root_node]\n",
    "    \n",
    "    while len(agenda)>0:\n",
    "        \n",
    "    processed_nodes = analyze_with_lm(graph, lm)\n",
    "    \n",
    "    for each_processed_node in processed_nodes:\n",
    "        nodes_for_next_step = analyze_with_lm(graph, lm, start_node=each_processed_node)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_node = GraphNode()\n",
    "\n",
    "мамамыла\n",
    "мама\n",
    "мыла \n",
    "рыла\n",
    "раму\n",
    "ламу\n",
    "маму\n",
    "мамамылараму\n",
    "мылом\n",
    "мы\n",
    "лом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "\n",
    "root_node = \"<S\" \n",
    "\n",
    "mamamila_12 = \"мамамыла\" \n",
    "mama_1 = \"мама\" \n",
    "dama_1 = \"дама\" \n",
    "\n",
    "mila_2 = \"мыла\" \n",
    "rila_2 = \"рыла\" \n",
    "\n",
    "ramu_3 = \"раму\"\n",
    "lamu_3 = \"ламу\" \n",
    "\n",
    "mi_4 = \"мы\"\n",
    "lom_5 = \"лом\"\n",
    "milom_45 = \"мылом\"\n",
    "\n",
    "fin_node = \"S>\" \n",
    "\n",
    "# G.add_node(root_node)\n",
    "\n",
    "# G.add_node(mamamila_12)\n",
    "# G.add_node(mama_1)\n",
    "# G.add_node(dama_1)\n",
    "\n",
    "# G.add_node(fin_node)\n",
    "\n",
    "G.add_edge(root_node, mamamila_12)\n",
    "G.add_edge(root_node, mama_1)\n",
    "G.add_edge(root_node, dama_1)\n",
    "\n",
    "G.add_edge(mama_1, mila_2)\n",
    "G.add_edge(dama_1, mila_2)\n",
    "G.add_edge(mama_1, rila_2)\n",
    "G.add_edge(dama_1, rila_2)\n",
    "\n",
    "G.add_edge(mamamila_12, ramu_3)\n",
    "G.add_edge(mamamila_12, lamu_3)\n",
    "G.add_edge(mila_2, ramu_3)\n",
    "G.add_edge(mila_2, lamu_3)\n",
    "G.add_edge(rila_2, ramu_3)\n",
    "G.add_edge(rila_2, lamu_3)\n",
    "\n",
    "G.add_edge(ramu_3, mi_4)\n",
    "G.add_edge(ramu_3, milom_45)\n",
    "\n",
    "G.add_edge(lamu_3, mi_4)\n",
    "G.add_edge(lamu_3, milom_45)\n",
    "\n",
    "\n",
    "G.add_edge(mi_4, lom_5)\n",
    "\n",
    "G.add_edge(milom_45, fin_node)\n",
    "G.add_edge(lom_5, fin_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f484c3490b8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# g1 = nx.petersen_graph()\n",
    "# pos = nx.spring_layout(G)\n",
    "pos = nx.shell_layout(G)\n",
    "nx.draw_networkx_nodes(G, pos, node_color='g',\n",
    "                       node_size = 500)\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "nx.draw_networkx_edges(G, pos, edge_color='r', arrows=True)\n",
    "# nx.draw_networkx_edges(G, pos, edgelist=black_edges, arrows=False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# nx.draw(G)\n",
    "# nx.draw_networkx_labels(G, pos=nx.spring_layout(G))\n",
    "# # nx.draw_networkx_labels(G, pos=nx.random_layout(G))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"~/.deeppavlov\"\n",
    "DOWNLOADS_PATH = ROOT_PATH + \"/downloads\"        \n",
    "kenlm_model = KenlmElector(load_path=DOWNLOADS_PATH+\"/language_models/ru_wiyalen_no_punkt.arpa.binary\")\n",
    "# state = kenlm.State()\n",
    "\n",
    "def score_hypothesis_by_tokens(kenlm_model, sentence_hypothesis):\n",
    "    state = kenlm.State()\n",
    "    prev_state = state\n",
    "    kenlm_model.lm.BeginSentenceWrite(state)\n",
    "    \n",
    "    accum = 0.0\n",
    "    for each_tok_hyp in sentence_hypothesis.token_hypotheses:\n",
    "        next_state = kenlm.State()\n",
    "        uniscore=kenlm_model.lm.BaseScore(prev_state, each_tok_hyp.text, next_state)\n",
    "        if each_tok_hyp.merges_count>0:\n",
    "            # check each_tok_hyp is OOV! otherwise heuristics is incorrect\n",
    "            uniscore *= each_tok_hyp.merges_count+1\n",
    "        print(each_tok_hyp, uniscore)\n",
    "        accum += uniscore\n",
    "        prev_state = next_state\n",
    "        \n",
    "def score_hypothesis_by_tokens_nos(kenlm_model, sentence_hypothesis):\n",
    "    state = kenlm.State()\n",
    "    prev_state = state\n",
    "    kenlm_model.lm.NullContextWrite(state)\n",
    "    accum = 0.0\n",
    "    for each_tok_hyp in sentence_hypothesis.token_hypotheses:\n",
    "        next_state = kenlm.State()\n",
    "        uniscore=kenlm_model.lm.BaseScore(prev_state, each_tok_hyp.text, next_state)\n",
    "        if each_tok_hyp.merges_count>0:\n",
    "            # check each_tok_hyp is OOV! otherwise heuristics is incorrect\n",
    "            uniscore *= each_tok_hyp.merges_count+1\n",
    "#         print(each_tok_hyp, uniscore)\n",
    "        accum += uniscore\n",
    "        prev_state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trie Optimization Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datrie\n",
    "\n",
    "# alphabet of the language:\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz 1234567890абвгдеёжзиёклмнопрстуфхцчшщъыьэюя-'\n",
    "\n",
    "class TrieHypothesesManager():\n",
    "    def __init__(alphabet):\n",
    "        self.trie = datrie.Trie(alphabet)\n",
    "        \n",
    "    def push_hypotheses_hub(self, hypotheses):\n",
    "        pass\n",
    "    \n",
    "    def analyze_hypotheses_with_lm(self, lm):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def prune_hypotheses(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3",
   "language": "python",
   "name": ".venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
